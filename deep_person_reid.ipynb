{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbZUSFpjDAZs"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QP4TtGrHKIxF",
        "outputId": "afa65c6e-28bd-4680-fdb5-c1eaa25d38a8"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt\n",
        "\n",
        "# install torch and torchvision (select the proper cuda version to suit your machine)\n",
        "%pip install pytorch torchvision cudatoolkit=9.0 -c pytorch\n",
        "\n",
        "# install torchreid (don't need to re-build it if you modify the source code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling torchreid/metrics/rank_cylib/rank_cy.pyx because it changed.\n",
            "[1/1] Cythonizing torchreid/metrics/rank_cylib/rank_cy.pyx\n",
            "running develop\n",
            "running egg_info\n",
            "creating torchreid.egg-info\n",
            "writing torchreid.egg-info\\PKG-INFO\n",
            "writing dependency_links to torchreid.egg-info\\dependency_links.txt\n",
            "writing requirements to torchreid.egg-info\\requires.txt\n",
            "writing top-level names to torchreid.egg-info\\top_level.txt\n",
            "writing manifest file 'torchreid.egg-info\\SOURCES.txt'\n",
            "dependency c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
            "dependency c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
            "dependency c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
            "dependency c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
            "dependency c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
            "reading manifest file 'torchreid.egg-info\\SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'torchreid.egg-info\\SOURCES.txt'\n",
            "running build_ext\n",
            "building 'torchreid.metrics.rank_cylib.rank_cy' extension\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\DANC\\deep-person-reid\\torchreid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\Cython\\Compiler\\Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: d:\\DANC\\deep-person-reid\\torchreid\\metrics\\rank_cylib\\rank_cy.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\setuptools\\command\\develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "c:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py:79: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n"
          ]
        }
      ],
      "source": [
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dYoobey8gAfF"
      },
      "outputs": [],
      "source": [
        "!mkdir reid-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjxQ3NOwu1lv"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vVAS4QpjZbU7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\DANC\\deep-person-reid\\torchreid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torchreid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucBN03d5h7yt",
        "outputId": "a5849e66-f100-4f6b-bd33-9d4526f78132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building train transforms ...\n",
            "+ resize to 128x128\n",
            "+ random flip\n",
            "+ random crop (enlarge to 144x144 and crop 128x128)\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "Building test transforms ...\n",
            "+ resize to 128x128\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "=> Loading train (source) dataset\n",
            "=> Loaded EndoCV\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    51 |     1454 |         8\n",
            "  query    |    51 |      262 |         8\n",
            "  gallery  |    51 |      507 |         1\n",
            "  ----------------------------------------\n",
            "=> Loading test (target) dataset\n",
            "=> Loaded EndoCV\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    51 |     1454 |         8\n",
            "  query    |    51 |      262 |         8\n",
            "  gallery  |    51 |      507 |         1\n",
            "  ----------------------------------------\n",
            "\n",
            "\n",
            "  **************** Summary ****************\n",
            "  source            : ['endocv']\n",
            "  # source datasets : 1\n",
            "  # source ids      : 51\n",
            "  # source images   : 1454\n",
            "  # source cameras  : 8\n",
            "  target            : ['endocv']\n",
            "  *****************************************\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\DANC\\deep-person-reid\\torchreid\\data\\datasets\\image\\endocv.py:34: UserWarning: The current data structure is deprecated. Please put data folders such as \"bounding_box_train\" under \"Market-1501-v15.09.15\".\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "datamanager = torchreid.data.ImageDataManager(\n",
        "    root=\"reid-data\",\n",
        "    sources=\"endocv\",\n",
        "    targets=\"endocv\",\n",
        "    height=128,\n",
        "    width=128,\n",
        "    batch_size_train=32,\n",
        "    batch_size_test=100,\n",
        "    transforms=[\"random_flip\", \"random_crop\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpsAW1FLiMmM",
        "outputId": "e992d5a9-1a20-496b-c735-6db7ca59a1c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded imagenet pretrained weights from \"C:\\Users\\Admin/.cache\\torch\\checkpoints\\osnet_x0_25_imagenet.pth\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['conv5.conv.weight', 'classifier.weight', 'classifier.bias']\n"
          ]
        }
      ],
      "source": [
        "model = torchreid.models.build_model(\n",
        "    name=\"osnet_dcn_x0_25_endocv\", #osnet_x0_25\n",
        "    num_classes=datamanager.num_train_pids,\n",
        "    loss=\"softmax\",\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torchreid.optim.build_optimizer(\n",
        "    model,\n",
        "    optim=\"adam\",\n",
        "    lr=0.0003\n",
        ")\n",
        "\n",
        "scheduler = torchreid.optim.build_lr_scheduler(\n",
        "    optimizer,\n",
        "    lr_scheduler=\"single_step\",\n",
        "    stepsize=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yRmmuEMxiNq3"
      },
      "outputs": [],
      "source": [
        "engine = torchreid.engine.ImageSoftmaxEngine(\n",
        "    datamanager,\n",
        "    model,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    label_smooth=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PeJY9zKiSpf",
        "outputId": "5a96797a-7a1e-4081-ffdb-078e8447cb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Start training\n",
            "epoch: [1/100][10/45]\ttime 0.115 (2.414)\tdata 0.000 (2.230)\teta 3:00:36\tloss 3.6228 (3.8075)\tacc 18.7500 (10.6250)\tlr 0.000300\n",
            "epoch: [1/100][20/45]\ttime 0.109 (1.267)\tdata 0.000 (1.115)\teta 1:34:35\tloss 3.1680 (3.6517)\tacc 25.0000 (14.5312)\tlr 0.000300\n",
            "epoch: [1/100][30/45]\ttime 0.119 (0.886)\tdata 0.001 (0.744)\teta 1:06:00\tloss 3.2916 (3.5523)\tacc 15.6250 (15.4167)\tlr 0.000300\n",
            "epoch: [1/100][40/45]\ttime 0.082 (0.693)\tdata 0.000 (0.558)\teta 0:51:29\tloss 3.0721 (3.4583)\tacc 31.2500 (18.5156)\tlr 0.000300\n",
            "epoch: [2/100][10/45]\ttime 0.101 (2.315)\tdata 0.000 (2.200)\teta 2:51:30\tloss 2.9540 (2.8142)\tacc 31.2500 (36.2500)\tlr 0.000300\n",
            "epoch: [2/100][20/45]\ttime 0.105 (1.210)\tdata 0.000 (1.100)\teta 1:29:26\tloss 2.9454 (2.8202)\tacc 28.1250 (35.6250)\tlr 0.000300\n",
            "epoch: [2/100][30/45]\ttime 0.109 (0.845)\tdata 0.001 (0.734)\teta 1:02:21\tloss 2.5018 (2.7769)\tacc 53.1250 (36.3542)\tlr 0.000300\n",
            "epoch: [2/100][40/45]\ttime 0.091 (0.661)\tdata 0.000 (0.550)\teta 0:48:40\tloss 2.3495 (2.7328)\tacc 50.0000 (37.5781)\tlr 0.000300\n",
            "epoch: [3/100][10/45]\ttime 0.092 (2.299)\tdata 0.001 (2.185)\teta 2:48:36\tloss 2.1892 (2.3692)\tacc 53.1250 (46.8750)\tlr 0.000300\n",
            "epoch: [3/100][20/45]\ttime 0.109 (1.204)\tdata 0.000 (1.092)\teta 1:28:04\tloss 2.3053 (2.3687)\tacc 53.1250 (47.0312)\tlr 0.000300\n",
            "epoch: [3/100][30/45]\ttime 0.096 (0.839)\tdata 0.001 (0.729)\teta 1:01:16\tloss 2.2761 (2.3173)\tacc 56.2500 (49.3750)\tlr 0.000300\n",
            "epoch: [3/100][40/45]\ttime 0.080 (0.657)\tdata 0.000 (0.547)\teta 0:47:51\tloss 2.1473 (2.3039)\tacc 62.5000 (49.2188)\tlr 0.000300\n",
            "epoch: [4/100][10/45]\ttime 0.093 (2.303)\tdata 0.001 (2.187)\teta 2:47:09\tloss 2.1866 (1.9873)\tacc 46.8750 (62.1875)\tlr 0.000300\n",
            "epoch: [4/100][20/45]\ttime 0.097 (1.204)\tdata 0.001 (1.094)\teta 1:27:13\tloss 1.9333 (1.9559)\tacc 65.6250 (62.9688)\tlr 0.000300\n",
            "epoch: [4/100][30/45]\ttime 0.105 (0.841)\tdata 0.000 (0.729)\teta 1:00:46\tloss 1.9009 (1.9638)\tacc 68.7500 (62.7083)\tlr 0.000300\n",
            "epoch: [4/100][40/45]\ttime 0.075 (0.658)\tdata 0.001 (0.547)\teta 0:47:24\tloss 1.9152 (1.9407)\tacc 59.3750 (63.8281)\tlr 0.000300\n",
            "epoch: [5/100][10/45]\ttime 0.110 (2.252)\tdata 0.000 (2.134)\teta 2:41:44\tloss 1.5855 (1.6622)\tacc 81.2500 (77.1875)\tlr 0.000300\n",
            "epoch: [5/100][20/45]\ttime 0.095 (1.178)\tdata 0.000 (1.067)\teta 1:24:26\tloss 1.8539 (1.7666)\tacc 62.5000 (70.7812)\tlr 0.000300\n",
            "epoch: [5/100][30/45]\ttime 0.106 (0.823)\tdata 0.000 (0.711)\teta 0:58:48\tloss 1.6152 (1.7597)\tacc 78.1250 (70.4167)\tlr 0.000300\n",
            "epoch: [5/100][40/45]\ttime 0.085 (0.645)\tdata 0.001 (0.534)\teta 0:46:00\tloss 1.7897 (1.7310)\tacc 78.1250 (71.8750)\tlr 0.000300\n",
            "epoch: [6/100][10/45]\ttime 0.100 (2.321)\tdata 0.000 (2.201)\teta 2:44:57\tloss 1.5061 (1.5620)\tacc 78.1250 (76.2500)\tlr 0.000300\n",
            "epoch: [6/100][20/45]\ttime 0.113 (1.214)\tdata 0.000 (1.101)\teta 1:26:06\tloss 1.5534 (1.5448)\tacc 78.1250 (76.0938)\tlr 0.000300\n",
            "epoch: [6/100][30/45]\ttime 0.121 (0.849)\tdata 0.000 (0.734)\teta 1:00:02\tloss 1.5687 (1.5260)\tacc 78.1250 (77.5000)\tlr 0.000300\n",
            "epoch: [6/100][40/45]\ttime 0.078 (0.664)\tdata 0.000 (0.550)\teta 0:46:53\tloss 1.6191 (1.5215)\tacc 71.8750 (77.3438)\tlr 0.000300\n",
            "epoch: [7/100][10/45]\ttime 0.096 (2.255)\tdata 0.000 (2.140)\teta 2:38:36\tloss 1.3036 (1.3380)\tacc 87.5000 (83.4375)\tlr 0.000300\n",
            "epoch: [7/100][20/45]\ttime 0.111 (1.182)\tdata 0.000 (1.070)\teta 1:22:57\tloss 1.2510 (1.3452)\tacc 84.3750 (82.8125)\tlr 0.000300\n",
            "epoch: [7/100][30/45]\ttime 0.111 (0.825)\tdata 0.000 (0.714)\teta 0:57:45\tloss 1.3921 (1.3597)\tacc 75.0000 (82.2917)\tlr 0.000300\n",
            "epoch: [7/100][40/45]\ttime 0.079 (0.647)\tdata 0.000 (0.535)\teta 0:45:10\tloss 1.5241 (1.3566)\tacc 71.8750 (82.3438)\tlr 0.000300\n",
            "epoch: [8/100][10/45]\ttime 0.080 (2.235)\tdata 0.000 (2.119)\teta 2:35:32\tloss 1.2744 (1.2791)\tacc 84.3750 (85.9375)\tlr 0.000300\n",
            "epoch: [8/100][20/45]\ttime 0.095 (1.170)\tdata 0.000 (1.060)\teta 1:21:12\tloss 1.2648 (1.2702)\tacc 90.6250 (84.6875)\tlr 0.000300\n",
            "epoch: [8/100][30/45]\ttime 0.127 (0.819)\tdata 0.000 (0.706)\teta 0:56:41\tloss 1.4150 (1.2754)\tacc 75.0000 (84.0625)\tlr 0.000300\n",
            "epoch: [8/100][40/45]\ttime 0.095 (0.641)\tdata 0.000 (0.530)\teta 0:44:18\tloss 1.2420 (1.2634)\tacc 87.5000 (84.8438)\tlr 0.000300\n",
            "epoch: [9/100][10/45]\ttime 0.079 (2.268)\tdata 0.000 (2.150)\teta 2:36:06\tloss 1.1448 (1.1680)\tacc 90.6250 (92.1875)\tlr 0.000300\n",
            "epoch: [9/100][20/45]\ttime 0.112 (1.187)\tdata 0.000 (1.075)\teta 1:21:31\tloss 1.2036 (1.1765)\tacc 78.1250 (89.5312)\tlr 0.000300\n",
            "epoch: [9/100][30/45]\ttime 0.112 (0.829)\tdata 0.000 (0.717)\teta 0:56:47\tloss 1.2414 (1.1831)\tacc 84.3750 (89.4792)\tlr 0.000300\n",
            "epoch: [9/100][40/45]\ttime 0.096 (0.649)\tdata 0.000 (0.538)\teta 0:44:19\tloss 1.2855 (1.1844)\tacc 81.2500 (89.2969)\tlr 0.000300\n",
            "epoch: [10/100][10/45]\ttime 0.038 (2.197)\tdata 0.000 (2.148)\teta 2:29:33\tloss 1.0428 (1.1142)\tacc 93.7500 (90.9375)\tlr 0.000300\n",
            "epoch: [10/100][20/45]\ttime 0.046 (1.123)\tdata 0.000 (1.075)\teta 1:16:14\tloss 1.1877 (1.1419)\tacc 87.5000 (90.1562)\tlr 0.000300\n",
            "epoch: [10/100][30/45]\ttime 0.038 (0.767)\tdata 0.000 (0.722)\teta 0:51:58\tloss 0.9092 (1.1399)\tacc 100.0000 (90.4167)\tlr 0.000300\n",
            "epoch: [10/100][40/45]\ttime 0.037 (0.588)\tdata 0.000 (0.542)\teta 0:39:44\tloss 1.0993 (1.1261)\tacc 90.6250 (90.2344)\tlr 0.000300\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0634 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 63.9%\n",
            "CMC curve\n",
            "Rank-1  : 81.0%\n",
            "Rank-5  : 93.7%\n",
            "Rank-10 : 94.9%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-10\"\n",
            "epoch: [11/100][10/45]\ttime 0.096 (2.267)\tdata 0.000 (2.154)\teta 2:32:37\tloss 1.0653 (1.0680)\tacc 93.7500 (93.1250)\tlr 0.000300\n",
            "epoch: [11/100][20/45]\ttime 0.110 (1.186)\tdata 0.000 (1.077)\teta 1:19:39\tloss 1.1309 (1.0845)\tacc 81.2500 (92.0312)\tlr 0.000300\n",
            "epoch: [11/100][30/45]\ttime 0.111 (0.829)\tdata 0.000 (0.718)\teta 0:55:31\tloss 0.9960 (1.0783)\tacc 100.0000 (91.8750)\tlr 0.000300\n",
            "epoch: [11/100][40/45]\ttime 0.079 (0.649)\tdata 0.000 (0.539)\teta 0:43:22\tloss 0.9945 (1.0921)\tacc 93.7500 (91.1719)\tlr 0.000300\n",
            "epoch: [12/100][10/45]\ttime 0.093 (2.289)\tdata 0.000 (2.172)\teta 2:32:24\tloss 1.0087 (1.0381)\tacc 93.7500 (93.1250)\tlr 0.000300\n",
            "epoch: [12/100][20/45]\ttime 0.103 (1.196)\tdata 0.000 (1.086)\teta 1:19:24\tloss 0.9468 (1.0359)\tacc 100.0000 (93.2812)\tlr 0.000300\n",
            "epoch: [12/100][30/45]\ttime 0.111 (0.834)\tdata 0.000 (0.724)\teta 0:55:13\tloss 1.1275 (1.0535)\tacc 90.6250 (92.5000)\tlr 0.000300\n",
            "epoch: [12/100][40/45]\ttime 0.095 (0.650)\tdata 0.000 (0.543)\teta 0:42:58\tloss 1.1241 (1.0486)\tacc 87.5000 (92.8906)\tlr 0.000300\n",
            "epoch: [13/100][10/45]\ttime 0.101 (2.263)\tdata 0.000 (2.145)\teta 2:29:00\tloss 1.1163 (1.0179)\tacc 87.5000 (93.4375)\tlr 0.000300\n",
            "epoch: [13/100][20/45]\ttime 0.095 (1.183)\tdata 0.000 (1.072)\teta 1:17:40\tloss 1.2136 (1.0294)\tacc 81.2500 (92.6562)\tlr 0.000300\n",
            "epoch: [13/100][30/45]\ttime 0.110 (0.826)\tdata 0.000 (0.715)\teta 0:54:06\tloss 1.1767 (1.0296)\tacc 90.6250 (93.4375)\tlr 0.000300\n",
            "epoch: [13/100][40/45]\ttime 0.094 (0.649)\tdata 0.000 (0.537)\teta 0:42:23\tloss 0.9994 (1.0184)\tacc 100.0000 (93.9844)\tlr 0.000300\n",
            "epoch: [14/100][10/45]\ttime 0.110 (2.275)\tdata 0.000 (2.152)\teta 2:28:03\tloss 0.9372 (0.9760)\tacc 100.0000 (95.0000)\tlr 0.000300\n",
            "epoch: [14/100][20/45]\ttime 0.095 (1.188)\tdata 0.000 (1.076)\teta 1:17:09\tloss 0.9705 (1.0006)\tacc 96.8750 (94.5312)\tlr 0.000300\n",
            "epoch: [14/100][30/45]\ttime 0.111 (0.829)\tdata 0.000 (0.718)\teta 0:53:41\tloss 1.0500 (1.0059)\tacc 87.5000 (93.3333)\tlr 0.000300\n",
            "epoch: [14/100][40/45]\ttime 0.094 (0.648)\tdata 0.000 (0.538)\teta 0:41:50\tloss 1.0255 (1.0037)\tacc 90.6250 (93.6719)\tlr 0.000300\n",
            "epoch: [15/100][10/45]\ttime 0.094 (2.245)\tdata 0.000 (2.129)\teta 2:24:26\tloss 0.9358 (0.9599)\tacc 93.7500 (95.3125)\tlr 0.000300\n",
            "epoch: [15/100][20/45]\ttime 0.100 (1.173)\tdata 0.000 (1.065)\teta 1:15:16\tloss 1.0640 (0.9733)\tacc 93.7500 (93.7500)\tlr 0.000300\n",
            "epoch: [15/100][30/45]\ttime 0.110 (0.819)\tdata 0.000 (0.710)\teta 0:52:23\tloss 1.0485 (0.9721)\tacc 93.7500 (94.4792)\tlr 0.000300\n",
            "epoch: [15/100][40/45]\ttime 0.079 (0.640)\tdata 0.000 (0.533)\teta 0:40:51\tloss 0.8961 (0.9677)\tacc 96.8750 (94.9219)\tlr 0.000300\n",
            "epoch: [16/100][10/45]\ttime 0.095 (2.268)\tdata 0.000 (2.157)\teta 2:24:12\tloss 0.8996 (0.9282)\tacc 100.0000 (96.5625)\tlr 0.000300\n",
            "epoch: [16/100][20/45]\ttime 0.096 (1.185)\tdata 0.000 (1.078)\teta 1:15:10\tloss 0.9472 (0.9342)\tacc 93.7500 (96.0938)\tlr 0.000300\n",
            "epoch: [16/100][30/45]\ttime 0.111 (0.827)\tdata 0.000 (0.719)\teta 0:52:19\tloss 0.9683 (0.9433)\tacc 96.8750 (96.0417)\tlr 0.000300\n",
            "epoch: [16/100][40/45]\ttime 0.079 (0.647)\tdata 0.000 (0.540)\teta 0:40:49\tloss 0.9659 (0.9406)\tacc 93.7500 (96.3281)\tlr 0.000300\n",
            "epoch: [17/100][10/45]\ttime 0.095 (2.262)\tdata 0.000 (2.144)\teta 2:22:07\tloss 0.9026 (0.9415)\tacc 100.0000 (96.5625)\tlr 0.000300\n",
            "epoch: [17/100][20/45]\ttime 0.095 (1.183)\tdata 0.000 (1.072)\teta 1:14:06\tloss 0.8470 (0.9423)\tacc 96.8750 (95.9375)\tlr 0.000300\n",
            "epoch: [17/100][30/45]\ttime 0.127 (0.825)\tdata 0.000 (0.715)\teta 0:51:33\tloss 1.0550 (0.9554)\tacc 87.5000 (95.1042)\tlr 0.000300\n",
            "epoch: [17/100][40/45]\ttime 0.098 (0.645)\tdata 0.016 (0.537)\teta 0:40:13\tloss 0.9191 (0.9561)\tacc 93.7500 (95.0781)\tlr 0.000300\n",
            "epoch: [18/100][10/45]\ttime 0.101 (2.366)\tdata 0.000 (2.225)\teta 2:26:53\tloss 0.9193 (0.9336)\tacc 96.8750 (95.9375)\tlr 0.000300\n",
            "epoch: [18/100][20/45]\ttime 0.109 (1.235)\tdata 0.000 (1.113)\teta 1:16:27\tloss 1.0137 (0.9230)\tacc 93.7500 (96.2500)\tlr 0.000300\n",
            "epoch: [18/100][30/45]\ttime 0.105 (0.861)\tdata 0.000 (0.742)\teta 0:53:08\tloss 0.9073 (0.9228)\tacc 96.8750 (96.4583)\tlr 0.000300\n",
            "epoch: [18/100][40/45]\ttime 0.079 (0.672)\tdata 0.000 (0.556)\teta 0:41:22\tloss 0.9422 (0.9248)\tacc 100.0000 (96.5625)\tlr 0.000300\n",
            "epoch: [19/100][10/45]\ttime 0.095 (2.315)\tdata 0.000 (2.201)\teta 2:22:00\tloss 0.9075 (0.8810)\tacc 96.8750 (98.4375)\tlr 0.000300\n",
            "epoch: [19/100][20/45]\ttime 0.106 (1.210)\tdata 0.001 (1.101)\teta 1:13:59\tloss 0.9075 (0.8940)\tacc 96.8750 (97.5000)\tlr 0.000300\n",
            "epoch: [19/100][30/45]\ttime 0.122 (0.844)\tdata 0.001 (0.734)\teta 0:51:29\tloss 0.9019 (0.9076)\tacc 100.0000 (96.5625)\tlr 0.000300\n",
            "epoch: [19/100][40/45]\ttime 0.089 (0.662)\tdata 0.001 (0.551)\teta 0:40:14\tloss 0.8616 (0.9123)\tacc 100.0000 (96.3281)\tlr 0.000300\n",
            "epoch: [20/100][10/45]\ttime 0.103 (2.362)\tdata 0.003 (2.247)\teta 2:23:04\tloss 1.0682 (0.9013)\tacc 93.7500 (98.1250)\tlr 0.000300\n",
            "epoch: [20/100][20/45]\ttime 0.096 (1.230)\tdata 0.000 (1.124)\teta 1:14:18\tloss 0.9598 (0.9083)\tacc 93.7500 (97.8125)\tlr 0.000300\n",
            "epoch: [20/100][30/45]\ttime 0.120 (0.856)\tdata 0.001 (0.749)\teta 0:51:36\tloss 0.8886 (0.9044)\tacc 96.8750 (97.1875)\tlr 0.000300\n",
            "epoch: [20/100][40/45]\ttime 0.088 (0.668)\tdata 0.000 (0.562)\teta 0:40:09\tloss 0.8752 (0.9011)\tacc 96.8750 (97.1094)\tlr 0.000300\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0292 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 69.2%\n",
            "CMC curve\n",
            "Rank-1  : 88.6%\n",
            "Rank-5  : 95.4%\n",
            "Rank-10 : 97.0%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-20\"\n",
            "epoch: [21/100][10/45]\ttime 0.098 (2.316)\tdata 0.000 (2.202)\teta 2:18:35\tloss 0.8538 (0.8731)\tacc 100.0000 (98.4375)\tlr 0.000030\n",
            "epoch: [21/100][20/45]\ttime 0.103 (1.211)\tdata 0.000 (1.101)\teta 1:12:13\tloss 0.8442 (0.8766)\tacc 96.8750 (97.5000)\tlr 0.000030\n",
            "epoch: [21/100][30/45]\ttime 0.108 (0.846)\tdata 0.000 (0.734)\teta 0:50:18\tloss 0.8069 (0.8847)\tacc 100.0000 (97.5000)\tlr 0.000030\n",
            "epoch: [21/100][40/45]\ttime 0.106 (0.663)\tdata 0.001 (0.551)\teta 0:39:20\tloss 0.8273 (0.8754)\tacc 100.0000 (97.8125)\tlr 0.000030\n",
            "epoch: [22/100][10/45]\ttime 0.095 (2.226)\tdata 0.000 (2.112)\teta 2:11:30\tloss 0.8850 (0.8873)\tacc 96.8750 (97.5000)\tlr 0.000030\n",
            "epoch: [22/100][20/45]\ttime 0.111 (1.165)\tdata 0.000 (1.056)\teta 1:08:38\tloss 0.8172 (0.8722)\tacc 100.0000 (98.2812)\tlr 0.000030\n",
            "epoch: [22/100][30/45]\ttime 0.110 (0.813)\tdata 0.000 (0.704)\teta 0:47:44\tloss 0.9500 (0.8696)\tacc 90.6250 (97.8125)\tlr 0.000030\n",
            "epoch: [22/100][40/45]\ttime 0.079 (0.638)\tdata 0.000 (0.528)\teta 0:37:22\tloss 0.9004 (0.8763)\tacc 96.8750 (97.6562)\tlr 0.000030\n",
            "epoch: [23/100][10/45]\ttime 0.096 (2.216)\tdata 0.000 (2.105)\teta 2:09:16\tloss 0.8278 (0.8827)\tacc 100.0000 (97.1875)\tlr 0.000030\n",
            "epoch: [23/100][20/45]\ttime 0.111 (1.160)\tdata 0.000 (1.053)\teta 1:07:29\tloss 0.8494 (0.8849)\tacc 96.8750 (96.8750)\tlr 0.000030\n",
            "epoch: [23/100][30/45]\ttime 0.125 (0.809)\tdata 0.000 (0.703)\teta 0:46:57\tloss 0.7989 (0.8713)\tacc 100.0000 (97.2917)\tlr 0.000030\n",
            "epoch: [23/100][40/45]\ttime 0.080 (0.633)\tdata 0.000 (0.528)\teta 0:36:36\tloss 0.8390 (0.8707)\tacc 100.0000 (97.6562)\tlr 0.000030\n",
            "epoch: [24/100][10/45]\ttime 0.094 (2.212)\tdata 0.000 (2.105)\teta 2:07:24\tloss 0.8709 (0.8450)\tacc 96.8750 (98.7500)\tlr 0.000030\n",
            "epoch: [24/100][20/45]\ttime 0.095 (1.158)\tdata 0.000 (1.052)\teta 1:06:28\tloss 0.8167 (0.8444)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [24/100][30/45]\ttime 0.110 (0.808)\tdata 0.000 (0.702)\teta 0:46:15\tloss 0.8599 (0.8462)\tacc 96.8750 (98.5417)\tlr 0.000030\n",
            "epoch: [24/100][40/45]\ttime 0.079 (0.631)\tdata 0.000 (0.526)\teta 0:36:02\tloss 0.8253 (0.8495)\tacc 96.8750 (98.2812)\tlr 0.000030\n",
            "epoch: [25/100][10/45]\ttime 0.101 (2.214)\tdata 0.000 (2.103)\teta 2:05:51\tloss 0.8044 (0.8388)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [25/100][20/45]\ttime 0.095 (1.157)\tdata 0.000 (1.052)\teta 1:05:33\tloss 0.8744 (0.8537)\tacc 96.8750 (98.1250)\tlr 0.000030\n",
            "epoch: [25/100][30/45]\ttime 0.142 (0.807)\tdata 0.000 (0.701)\teta 0:45:36\tloss 0.8931 (0.8561)\tacc 96.8750 (98.3333)\tlr 0.000030\n",
            "epoch: [25/100][40/45]\ttime 0.080 (0.631)\tdata 0.000 (0.527)\teta 0:35:33\tloss 0.7968 (0.8524)\tacc 100.0000 (98.6719)\tlr 0.000030\n",
            "epoch: [26/100][10/45]\ttime 0.096 (2.221)\tdata 0.000 (2.109)\teta 2:04:32\tloss 0.8469 (0.8497)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [26/100][20/45]\ttime 0.111 (1.163)\tdata 0.000 (1.055)\teta 1:05:01\tloss 0.8264 (0.8466)\tacc 100.0000 (99.2188)\tlr 0.000030\n",
            "epoch: [26/100][30/45]\ttime 0.111 (0.811)\tdata 0.000 (0.703)\teta 0:45:12\tloss 0.8416 (0.8437)\tacc 100.0000 (99.2708)\tlr 0.000030\n",
            "epoch: [26/100][40/45]\ttime 0.080 (0.634)\tdata 0.000 (0.527)\teta 0:35:15\tloss 0.8395 (0.8468)\tacc 100.0000 (98.9844)\tlr 0.000030\n",
            "epoch: [27/100][10/45]\ttime 0.111 (2.225)\tdata 0.000 (2.109)\teta 2:03:05\tloss 0.9384 (0.8532)\tacc 93.7500 (97.8125)\tlr 0.000030\n",
            "epoch: [27/100][20/45]\ttime 0.095 (1.163)\tdata 0.000 (1.055)\teta 1:04:09\tloss 0.8724 (0.8549)\tacc 96.8750 (97.8125)\tlr 0.000030\n",
            "epoch: [27/100][30/45]\ttime 0.113 (0.811)\tdata 0.000 (0.703)\teta 0:44:35\tloss 0.8286 (0.8465)\tacc 100.0000 (98.0208)\tlr 0.000030\n",
            "epoch: [27/100][40/45]\ttime 0.079 (0.635)\tdata 0.000 (0.527)\teta 0:34:47\tloss 0.9518 (0.8495)\tacc 93.7500 (98.1250)\tlr 0.000030\n",
            "epoch: [28/100][10/45]\ttime 0.111 (2.212)\tdata 0.016 (2.100)\teta 2:00:45\tloss 0.8760 (0.8388)\tacc 100.0000 (98.4375)\tlr 0.000030\n",
            "epoch: [28/100][20/45]\ttime 0.095 (1.157)\tdata 0.000 (1.050)\teta 1:02:59\tloss 0.8148 (0.8421)\tacc 96.8750 (97.9688)\tlr 0.000030\n",
            "epoch: [28/100][30/45]\ttime 0.111 (0.806)\tdata 0.000 (0.700)\teta 0:43:43\tloss 0.8221 (0.8451)\tacc 100.0000 (98.0208)\tlr 0.000030\n",
            "epoch: [28/100][40/45]\ttime 0.078 (0.630)\tdata 0.000 (0.525)\teta 0:34:04\tloss 0.8356 (0.8437)\tacc 100.0000 (98.1250)\tlr 0.000030\n",
            "epoch: [29/100][10/45]\ttime 0.095 (2.211)\tdata 0.000 (2.098)\teta 1:59:01\tloss 0.8609 (0.8383)\tacc 96.8750 (99.0625)\tlr 0.000030\n",
            "epoch: [29/100][20/45]\ttime 0.110 (1.156)\tdata 0.000 (1.049)\teta 1:02:02\tloss 0.8289 (0.8326)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [29/100][30/45]\ttime 0.126 (0.806)\tdata 0.000 (0.700)\teta 0:43:06\tloss 0.8128 (0.8397)\tacc 100.0000 (98.9583)\tlr 0.000030\n",
            "epoch: [29/100][40/45]\ttime 0.079 (0.631)\tdata 0.000 (0.525)\teta 0:33:37\tloss 0.8584 (0.8438)\tacc 100.0000 (98.8281)\tlr 0.000030\n",
            "epoch: [30/100][10/45]\ttime 0.094 (2.216)\tdata 0.000 (2.106)\teta 1:57:39\tloss 0.8397 (0.8478)\tacc 96.8750 (97.8125)\tlr 0.000030\n",
            "epoch: [30/100][20/45]\ttime 0.095 (1.159)\tdata 0.000 (1.053)\teta 1:01:19\tloss 0.8154 (0.8388)\tacc 100.0000 (98.2812)\tlr 0.000030\n",
            "epoch: [30/100][30/45]\ttime 0.110 (0.807)\tdata 0.000 (0.702)\teta 0:42:35\tloss 0.8793 (0.8396)\tacc 100.0000 (98.5417)\tlr 0.000030\n",
            "epoch: [30/100][40/45]\ttime 0.078 (0.631)\tdata 0.000 (0.527)\teta 0:33:10\tloss 0.8119 (0.8450)\tacc 100.0000 (98.3594)\tlr 0.000030\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0298 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 73.0%\n",
            "CMC curve\n",
            "Rank-1  : 88.6%\n",
            "Rank-5  : 94.1%\n",
            "Rank-10 : 95.8%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-30\"\n",
            "epoch: [31/100][10/45]\ttime 0.094 (2.217)\tdata 0.000 (2.104)\teta 1:56:00\tloss 0.8314 (0.8306)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [31/100][20/45]\ttime 0.110 (1.159)\tdata 0.000 (1.052)\teta 1:00:29\tloss 0.8047 (0.8337)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [31/100][30/45]\ttime 0.110 (0.808)\tdata 0.000 (0.701)\teta 0:42:01\tloss 0.8194 (0.8332)\tacc 100.0000 (98.8542)\tlr 0.000030\n",
            "epoch: [31/100][40/45]\ttime 0.079 (0.632)\tdata 0.000 (0.526)\teta 0:32:46\tloss 0.7897 (0.8306)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [32/100][10/45]\ttime 0.095 (2.212)\tdata 0.000 (2.099)\teta 1:54:06\tloss 0.8061 (0.8496)\tacc 100.0000 (98.1250)\tlr 0.000030\n",
            "epoch: [32/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.050)\teta 0:59:26\tloss 0.8760 (0.8487)\tacc 96.8750 (97.5000)\tlr 0.000030\n",
            "epoch: [32/100][30/45]\ttime 0.111 (0.807)\tdata 0.000 (0.700)\teta 0:41:22\tloss 0.8188 (0.8450)\tacc 100.0000 (98.0208)\tlr 0.000030\n",
            "epoch: [32/100][40/45]\ttime 0.081 (0.631)\tdata 0.000 (0.525)\teta 0:32:13\tloss 0.8392 (0.8468)\tacc 96.8750 (97.8906)\tlr 0.000030\n",
            "epoch: [33/100][10/45]\ttime 0.099 (2.201)\tdata 0.000 (2.085)\teta 1:51:53\tloss 0.8327 (0.8351)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [33/100][20/45]\ttime 0.099 (1.151)\tdata 0.000 (1.042)\teta 0:58:18\tloss 0.8923 (0.8423)\tacc 96.8750 (98.7500)\tlr 0.000030\n",
            "epoch: [33/100][30/45]\ttime 0.094 (0.801)\tdata 0.000 (0.695)\teta 0:40:28\tloss 0.8145 (0.8354)\tacc 100.0000 (98.9583)\tlr 0.000030\n",
            "epoch: [33/100][40/45]\ttime 0.078 (0.627)\tdata 0.000 (0.522)\teta 0:31:34\tloss 0.8438 (0.8370)\tacc 96.8750 (99.0625)\tlr 0.000030\n",
            "epoch: [34/100][10/45]\ttime 0.095 (2.208)\tdata 0.000 (2.096)\teta 1:50:34\tloss 1.0135 (0.8467)\tacc 93.7500 (98.4375)\tlr 0.000030\n",
            "epoch: [34/100][20/45]\ttime 0.095 (1.154)\tdata 0.000 (1.048)\teta 0:57:37\tloss 0.8192 (0.8461)\tacc 100.0000 (98.4375)\tlr 0.000030\n",
            "epoch: [34/100][30/45]\ttime 0.127 (0.806)\tdata 0.000 (0.700)\teta 0:40:04\tloss 0.8340 (0.8421)\tacc 100.0000 (98.5417)\tlr 0.000030\n",
            "epoch: [34/100][40/45]\ttime 0.079 (0.630)\tdata 0.000 (0.525)\teta 0:31:15\tloss 0.9579 (0.8440)\tacc 93.7500 (98.5156)\tlr 0.000030\n",
            "epoch: [35/100][10/45]\ttime 0.100 (2.224)\tdata 0.000 (2.106)\teta 1:49:41\tloss 0.7901 (0.8135)\tacc 100.0000 (99.3750)\tlr 0.000030\n",
            "epoch: [35/100][20/45]\ttime 0.110 (1.165)\tdata 0.000 (1.054)\teta 0:57:18\tloss 0.8604 (0.8234)\tacc 96.8750 (98.7500)\tlr 0.000030\n",
            "epoch: [35/100][30/45]\ttime 0.110 (0.814)\tdata 0.000 (0.703)\teta 0:39:52\tloss 0.7723 (0.8301)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [35/100][40/45]\ttime 0.096 (0.638)\tdata 0.000 (0.527)\teta 0:31:08\tloss 0.8720 (0.8310)\tacc 96.8750 (98.6719)\tlr 0.000030\n",
            "epoch: [36/100][10/45]\ttime 0.095 (2.203)\tdata 0.000 (2.091)\teta 1:47:03\tloss 0.8153 (0.8287)\tacc 100.0000 (99.3750)\tlr 0.000030\n",
            "epoch: [36/100][20/45]\ttime 0.098 (1.153)\tdata 0.000 (1.046)\teta 0:55:49\tloss 0.8090 (0.8302)\tacc 100.0000 (99.3750)\tlr 0.000030\n",
            "epoch: [36/100][30/45]\ttime 0.110 (0.805)\tdata 0.000 (0.698)\teta 0:38:49\tloss 0.8615 (0.8328)\tacc 96.8750 (99.0625)\tlr 0.000030\n",
            "epoch: [36/100][40/45]\ttime 0.091 (0.630)\tdata 0.000 (0.523)\teta 0:30:16\tloss 0.8342 (0.8312)\tacc 96.8750 (98.9844)\tlr 0.000030\n",
            "epoch: [37/100][10/45]\ttime 0.096 (2.201)\tdata 0.000 (2.083)\teta 1:45:16\tloss 0.7982 (0.8112)\tacc 100.0000 (100.0000)\tlr 0.000030\n",
            "epoch: [37/100][20/45]\ttime 0.096 (1.151)\tdata 0.000 (1.042)\teta 0:54:51\tloss 0.8620 (0.8190)\tacc 100.0000 (99.8438)\tlr 0.000030\n",
            "epoch: [37/100][30/45]\ttime 0.127 (0.804)\tdata 0.000 (0.695)\teta 0:38:10\tloss 0.8045 (0.8183)\tacc 100.0000 (99.7917)\tlr 0.000030\n",
            "epoch: [37/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.521)\teta 0:29:43\tloss 0.7818 (0.8211)\tacc 100.0000 (99.3750)\tlr 0.000030\n",
            "epoch: [38/100][10/45]\ttime 0.095 (2.200)\tdata 0.000 (2.084)\teta 1:43:35\tloss 0.8338 (0.8255)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [38/100][20/45]\ttime 0.094 (1.151)\tdata 0.000 (1.042)\teta 0:53:59\tloss 0.8110 (0.8156)\tacc 100.0000 (99.5312)\tlr 0.000030\n",
            "epoch: [38/100][30/45]\ttime 0.126 (0.804)\tdata 0.000 (0.695)\teta 0:37:34\tloss 0.8347 (0.8196)\tacc 96.8750 (99.0625)\tlr 0.000030\n",
            "epoch: [38/100][40/45]\ttime 0.095 (0.629)\tdata 0.000 (0.521)\teta 0:29:17\tloss 0.8338 (0.8216)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [39/100][10/45]\ttime 0.110 (2.200)\tdata 0.000 (2.088)\teta 1:41:55\tloss 0.7893 (0.8348)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [39/100][20/45]\ttime 0.095 (1.151)\tdata 0.000 (1.044)\teta 0:53:09\tloss 0.8938 (0.8345)\tacc 96.8750 (98.7500)\tlr 0.000030\n",
            "epoch: [39/100][30/45]\ttime 0.111 (0.803)\tdata 0.000 (0.696)\teta 0:36:55\tloss 0.8703 (0.8348)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [39/100][40/45]\ttime 0.078 (0.629)\tdata 0.000 (0.522)\teta 0:28:48\tloss 0.8713 (0.8380)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [40/100][10/45]\ttime 0.096 (2.205)\tdata 0.000 (2.092)\teta 1:40:29\tloss 0.7963 (0.8199)\tacc 100.0000 (99.0625)\tlr 0.000030\n",
            "epoch: [40/100][20/45]\ttime 0.114 (1.154)\tdata 0.000 (1.046)\teta 0:52:24\tloss 0.7909 (0.8310)\tacc 100.0000 (98.7500)\tlr 0.000030\n",
            "epoch: [40/100][30/45]\ttime 0.111 (0.805)\tdata 0.000 (0.698)\teta 0:36:25\tloss 0.8022 (0.8309)\tacc 100.0000 (98.8542)\tlr 0.000030\n",
            "epoch: [40/100][40/45]\ttime 0.079 (0.629)\tdata 0.000 (0.523)\teta 0:28:21\tloss 0.8485 (0.8286)\tacc 96.8750 (98.9062)\tlr 0.000030\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0281 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.4%\n",
            "CMC curve\n",
            "Rank-1  : 90.3%\n",
            "Rank-5  : 94.9%\n",
            "Rank-10 : 97.5%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-40\"\n",
            "epoch: [41/100][10/45]\ttime 0.096 (2.208)\tdata 0.000 (2.094)\teta 1:38:58\tloss 0.8323 (0.8215)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [41/100][20/45]\ttime 0.103 (1.154)\tdata 0.000 (1.047)\teta 0:51:33\tloss 0.7864 (0.8195)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [41/100][30/45]\ttime 0.107 (0.804)\tdata 0.000 (0.698)\teta 0:35:46\tloss 0.8495 (0.8180)\tacc 96.8750 (99.2708)\tlr 0.000003\n",
            "epoch: [41/100][40/45]\ttime 0.095 (0.630)\tdata 0.000 (0.523)\teta 0:27:54\tloss 0.8201 (0.8183)\tacc 100.0000 (99.2969)\tlr 0.000003\n",
            "epoch: [42/100][10/45]\ttime 0.095 (2.204)\tdata 0.000 (2.090)\teta 1:37:10\tloss 0.8670 (0.8252)\tacc 96.8750 (98.7500)\tlr 0.000003\n",
            "epoch: [42/100][20/45]\ttime 0.096 (1.154)\tdata 0.000 (1.045)\teta 0:50:41\tloss 0.8373 (0.8196)\tacc 96.8750 (99.0625)\tlr 0.000003\n",
            "epoch: [42/100][30/45]\ttime 0.095 (0.804)\tdata 0.000 (0.697)\teta 0:35:11\tloss 0.8291 (0.8198)\tacc 96.8750 (98.8542)\tlr 0.000003\n",
            "epoch: [42/100][40/45]\ttime 0.078 (0.629)\tdata 0.000 (0.523)\teta 0:27:24\tloss 0.8122 (0.8215)\tacc 100.0000 (98.9844)\tlr 0.000003\n",
            "epoch: [43/100][10/45]\ttime 0.095 (2.213)\tdata 0.000 (2.101)\teta 1:35:54\tloss 0.8252 (0.8228)\tacc 100.0000 (98.4375)\tlr 0.000003\n",
            "epoch: [43/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.050)\teta 0:49:55\tloss 0.8833 (0.8255)\tacc 96.8750 (98.5938)\tlr 0.000003\n",
            "epoch: [43/100][30/45]\ttime 0.094 (0.809)\tdata 0.002 (0.701)\teta 0:34:47\tloss 0.8069 (0.8261)\tacc 100.0000 (98.2292)\tlr 0.000003\n",
            "epoch: [43/100][40/45]\ttime 0.095 (0.634)\tdata 0.000 (0.526)\teta 0:27:08\tloss 0.8025 (0.8251)\tacc 100.0000 (98.3594)\tlr 0.000003\n",
            "epoch: [44/100][10/45]\ttime 0.079 (2.213)\tdata 0.000 (2.102)\teta 1:34:13\tloss 0.7936 (0.8312)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [44/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.051)\teta 0:49:03\tloss 0.7980 (0.8349)\tacc 100.0000 (99.0625)\tlr 0.000003\n",
            "epoch: [44/100][30/45]\ttime 0.127 (0.807)\tdata 0.000 (0.701)\teta 0:34:05\tloss 0.8529 (0.8303)\tacc 96.8750 (98.9583)\tlr 0.000003\n",
            "epoch: [44/100][40/45]\ttime 0.079 (0.632)\tdata 0.000 (0.526)\teta 0:26:35\tloss 0.8132 (0.8294)\tacc 100.0000 (98.9844)\tlr 0.000003\n",
            "epoch: [45/100][10/45]\ttime 0.094 (2.203)\tdata 0.000 (2.090)\teta 1:32:10\tloss 0.7776 (0.8247)\tacc 100.0000 (99.0625)\tlr 0.000003\n",
            "epoch: [45/100][20/45]\ttime 0.110 (1.153)\tdata 0.000 (1.045)\teta 0:48:03\tloss 0.8583 (0.8230)\tacc 100.0000 (99.2188)\tlr 0.000003\n",
            "epoch: [45/100][30/45]\ttime 0.110 (0.805)\tdata 0.000 (0.697)\teta 0:33:24\tloss 0.8316 (0.8206)\tacc 100.0000 (99.1667)\tlr 0.000003\n",
            "epoch: [45/100][40/45]\ttime 0.079 (0.631)\tdata 0.000 (0.523)\teta 0:26:04\tloss 0.8255 (0.8240)\tacc 96.8750 (99.1406)\tlr 0.000003\n",
            "epoch: [46/100][10/45]\ttime 0.094 (2.203)\tdata 0.000 (2.092)\teta 1:30:31\tloss 0.8173 (0.8114)\tacc 100.0000 (99.0625)\tlr 0.000003\n",
            "epoch: [46/100][20/45]\ttime 0.111 (1.155)\tdata 0.000 (1.047)\teta 0:47:15\tloss 0.7733 (0.8095)\tacc 100.0000 (99.2188)\tlr 0.000003\n",
            "epoch: [46/100][30/45]\ttime 0.110 (0.806)\tdata 0.000 (0.698)\teta 0:32:50\tloss 0.8209 (0.8149)\tacc 100.0000 (98.8542)\tlr 0.000003\n",
            "epoch: [46/100][40/45]\ttime 0.095 (0.631)\tdata 0.000 (0.524)\teta 0:25:36\tloss 0.8453 (0.8157)\tacc 100.0000 (98.9844)\tlr 0.000003\n",
            "epoch: [47/100][10/45]\ttime 0.095 (2.212)\tdata 0.000 (2.100)\teta 1:29:14\tloss 0.8604 (0.8096)\tacc 96.8750 (99.6875)\tlr 0.000003\n",
            "epoch: [47/100][20/45]\ttime 0.096 (1.157)\tdata 0.000 (1.050)\teta 0:46:28\tloss 0.8041 (0.8147)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [47/100][30/45]\ttime 0.127 (0.811)\tdata 0.000 (0.700)\teta 0:32:25\tloss 0.7915 (0.8207)\tacc 100.0000 (99.2708)\tlr 0.000003\n",
            "epoch: [47/100][40/45]\ttime 0.078 (0.634)\tdata 0.000 (0.525)\teta 0:25:14\tloss 0.8285 (0.8235)\tacc 100.0000 (99.1406)\tlr 0.000003\n",
            "epoch: [48/100][10/45]\ttime 0.095 (2.210)\tdata 0.000 (2.095)\teta 1:27:28\tloss 0.8016 (0.8187)\tacc 100.0000 (98.7500)\tlr 0.000003\n",
            "epoch: [48/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.048)\teta 0:45:33\tloss 0.8178 (0.8211)\tacc 100.0000 (98.9062)\tlr 0.000003\n",
            "epoch: [48/100][30/45]\ttime 0.095 (0.806)\tdata 0.000 (0.699)\teta 0:31:37\tloss 0.8529 (0.8210)\tacc 100.0000 (98.9583)\tlr 0.000003\n",
            "epoch: [48/100][40/45]\ttime 0.095 (0.630)\tdata 0.000 (0.524)\teta 0:24:38\tloss 0.7942 (0.8212)\tacc 100.0000 (98.9062)\tlr 0.000003\n",
            "epoch: [49/100][10/45]\ttime 0.096 (2.198)\tdata 0.000 (2.087)\teta 1:25:21\tloss 0.8119 (0.8354)\tacc 100.0000 (98.1250)\tlr 0.000003\n",
            "epoch: [49/100][20/45]\ttime 0.110 (1.151)\tdata 0.000 (1.043)\teta 0:44:29\tloss 0.8855 (0.8338)\tacc 96.8750 (98.2812)\tlr 0.000003\n",
            "epoch: [49/100][30/45]\ttime 0.112 (0.806)\tdata 0.000 (0.696)\teta 0:31:00\tloss 0.8660 (0.8313)\tacc 96.8750 (98.6458)\tlr 0.000003\n",
            "epoch: [49/100][40/45]\ttime 0.079 (0.630)\tdata 0.000 (0.522)\teta 0:24:09\tloss 0.8814 (0.8290)\tacc 90.6250 (98.5938)\tlr 0.000003\n",
            "epoch: [50/100][10/45]\ttime 0.094 (2.209)\tdata 0.000 (2.098)\teta 1:24:07\tloss 0.7895 (0.8143)\tacc 100.0000 (98.7500)\tlr 0.000003\n",
            "epoch: [50/100][20/45]\ttime 0.111 (1.157)\tdata 0.000 (1.049)\teta 0:43:53\tloss 0.8045 (0.8151)\tacc 100.0000 (98.9062)\tlr 0.000003\n",
            "epoch: [50/100][30/45]\ttime 0.110 (0.807)\tdata 0.000 (0.700)\teta 0:30:27\tloss 0.8352 (0.8170)\tacc 100.0000 (99.0625)\tlr 0.000003\n",
            "epoch: [50/100][40/45]\ttime 0.063 (0.631)\tdata 0.000 (0.525)\teta 0:23:42\tloss 0.8247 (0.8170)\tacc 96.8750 (98.8281)\tlr 0.000003\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0256 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.4%\n",
            "CMC curve\n",
            "Rank-1  : 89.9%\n",
            "Rank-5  : 95.4%\n",
            "Rank-10 : 97.5%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-50\"\n",
            "epoch: [51/100][10/45]\ttime 0.109 (2.208)\tdata 0.000 (2.093)\teta 1:22:26\tloss 0.8386 (0.8243)\tacc 100.0000 (99.0625)\tlr 0.000003\n",
            "epoch: [51/100][20/45]\ttime 0.094 (1.154)\tdata 0.000 (1.046)\teta 0:42:53\tloss 0.7927 (0.8207)\tacc 100.0000 (98.9062)\tlr 0.000003\n",
            "epoch: [51/100][30/45]\ttime 0.111 (0.806)\tdata 0.000 (0.698)\teta 0:29:49\tloss 0.8048 (0.8227)\tacc 100.0000 (98.6458)\tlr 0.000003\n",
            "epoch: [51/100][40/45]\ttime 0.079 (0.631)\tdata 0.000 (0.523)\teta 0:23:15\tloss 0.8033 (0.8242)\tacc 100.0000 (98.5938)\tlr 0.000003\n",
            "epoch: [52/100][10/45]\ttime 0.094 (2.207)\tdata 0.000 (2.090)\teta 1:20:44\tloss 0.8155 (0.8214)\tacc 100.0000 (100.0000)\tlr 0.000003\n",
            "epoch: [52/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.045)\teta 0:42:05\tloss 0.8045 (0.8238)\tacc 100.0000 (99.8438)\tlr 0.000003\n",
            "epoch: [52/100][30/45]\ttime 0.110 (0.806)\tdata 0.000 (0.697)\teta 0:29:13\tloss 0.7957 (0.8233)\tacc 100.0000 (99.5833)\tlr 0.000003\n",
            "epoch: [52/100][40/45]\ttime 0.079 (0.630)\tdata 0.000 (0.523)\teta 0:22:44\tloss 0.7983 (0.8227)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [53/100][10/45]\ttime 0.095 (2.207)\tdata 0.000 (2.097)\teta 1:19:05\tloss 0.7814 (0.7986)\tacc 100.0000 (99.6875)\tlr 0.000003\n",
            "epoch: [53/100][20/45]\ttime 0.095 (1.155)\tdata 0.000 (1.048)\teta 0:41:12\tloss 0.8252 (0.8122)\tacc 96.8750 (99.0625)\tlr 0.000003\n",
            "epoch: [53/100][30/45]\ttime 0.112 (0.807)\tdata 0.000 (0.699)\teta 0:28:38\tloss 0.8308 (0.8131)\tacc 100.0000 (99.2708)\tlr 0.000003\n",
            "epoch: [53/100][40/45]\ttime 0.079 (0.630)\tdata 0.000 (0.525)\teta 0:22:16\tloss 0.8196 (0.8155)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [54/100][10/45]\ttime 0.095 (2.211)\tdata 0.000 (2.102)\teta 1:17:34\tloss 0.8105 (0.8282)\tacc 100.0000 (98.7500)\tlr 0.000003\n",
            "epoch: [54/100][20/45]\ttime 0.095 (1.158)\tdata 0.000 (1.052)\teta 0:40:25\tloss 0.8703 (0.8321)\tacc 96.8750 (98.7500)\tlr 0.000003\n",
            "epoch: [54/100][30/45]\ttime 0.127 (0.808)\tdata 0.000 (0.702)\teta 0:28:05\tloss 0.8084 (0.8221)\tacc 100.0000 (99.0625)\tlr 0.000003\n",
            "epoch: [54/100][40/45]\ttime 0.080 (0.632)\tdata 0.000 (0.526)\teta 0:21:50\tloss 0.8058 (0.8267)\tacc 100.0000 (98.5156)\tlr 0.000003\n",
            "epoch: [55/100][10/45]\ttime 0.096 (2.198)\tdata 0.000 (2.084)\teta 1:15:28\tloss 0.8862 (0.8273)\tacc 93.7500 (99.3750)\tlr 0.000003\n",
            "epoch: [55/100][20/45]\ttime 0.095 (1.151)\tdata 0.000 (1.042)\teta 0:39:18\tloss 0.8355 (0.8210)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [55/100][30/45]\ttime 0.127 (0.804)\tdata 0.000 (0.695)\teta 0:27:19\tloss 0.8966 (0.8316)\tacc 93.7500 (98.8542)\tlr 0.000003\n",
            "epoch: [55/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.521)\teta 0:21:15\tloss 0.8092 (0.8275)\tacc 100.0000 (98.9062)\tlr 0.000003\n",
            "epoch: [56/100][10/45]\ttime 0.095 (2.213)\tdata 0.000 (2.098)\teta 1:14:19\tloss 0.8045 (0.8132)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [56/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.049)\teta 0:38:38\tloss 0.7998 (0.8144)\tacc 100.0000 (99.2188)\tlr 0.000003\n",
            "epoch: [56/100][30/45]\ttime 0.110 (0.806)\tdata 0.000 (0.699)\teta 0:26:48\tloss 0.8738 (0.8180)\tacc 96.8750 (99.2708)\tlr 0.000003\n",
            "epoch: [56/100][40/45]\ttime 0.079 (0.631)\tdata 0.000 (0.525)\teta 0:20:52\tloss 0.7815 (0.8167)\tacc 100.0000 (99.2188)\tlr 0.000003\n",
            "epoch: [57/100][10/45]\ttime 0.111 (2.195)\tdata 0.000 (2.079)\teta 1:12:04\tloss 0.8466 (0.8152)\tacc 96.8750 (99.3750)\tlr 0.000003\n",
            "epoch: [57/100][20/45]\ttime 0.105 (1.149)\tdata 0.000 (1.041)\teta 0:37:32\tloss 0.8705 (0.8248)\tacc 100.0000 (99.2188)\tlr 0.000003\n",
            "epoch: [57/100][30/45]\ttime 0.111 (0.801)\tdata 0.000 (0.694)\teta 0:26:02\tloss 0.7890 (0.8255)\tacc 100.0000 (98.9583)\tlr 0.000003\n",
            "epoch: [57/100][40/45]\ttime 0.080 (0.626)\tdata 0.000 (0.520)\teta 0:20:15\tloss 0.8129 (0.8257)\tacc 100.0000 (98.8281)\tlr 0.000003\n",
            "epoch: [58/100][10/45]\ttime 0.096 (2.206)\tdata 0.000 (2.087)\teta 1:10:46\tloss 0.9210 (0.8334)\tacc 93.7500 (98.1250)\tlr 0.000003\n",
            "epoch: [58/100][20/45]\ttime 0.111 (1.154)\tdata 0.000 (1.045)\teta 0:36:49\tloss 0.8918 (0.8322)\tacc 96.8750 (98.2812)\tlr 0.000003\n",
            "epoch: [58/100][30/45]\ttime 0.111 (0.805)\tdata 0.000 (0.697)\teta 0:25:34\tloss 0.8100 (0.8295)\tacc 100.0000 (98.3333)\tlr 0.000003\n",
            "epoch: [58/100][40/45]\ttime 0.080 (0.629)\tdata 0.000 (0.523)\teta 0:19:52\tloss 0.8038 (0.8268)\tacc 100.0000 (98.3594)\tlr 0.000003\n",
            "epoch: [59/100][10/45]\ttime 0.110 (2.199)\tdata 0.000 (2.086)\teta 1:08:54\tloss 0.8155 (0.8238)\tacc 96.8750 (98.7500)\tlr 0.000003\n",
            "epoch: [59/100][20/45]\ttime 0.095 (1.150)\tdata 0.000 (1.043)\teta 0:35:50\tloss 0.8173 (0.8199)\tacc 100.0000 (99.2188)\tlr 0.000003\n",
            "epoch: [59/100][30/45]\ttime 0.127 (0.802)\tdata 0.000 (0.696)\teta 0:24:51\tloss 0.8133 (0.8171)\tacc 96.8750 (99.2708)\tlr 0.000003\n",
            "epoch: [59/100][40/45]\ttime 0.079 (0.627)\tdata 0.000 (0.522)\teta 0:19:20\tloss 0.8906 (0.8146)\tacc 93.7500 (99.2188)\tlr 0.000003\n",
            "epoch: [60/100][10/45]\ttime 0.094 (2.191)\tdata 0.000 (2.082)\teta 1:07:01\tloss 0.8144 (0.8147)\tacc 100.0000 (100.0000)\tlr 0.000003\n",
            "epoch: [60/100][20/45]\ttime 0.095 (1.148)\tdata 0.000 (1.041)\teta 0:34:54\tloss 0.8480 (0.8143)\tacc 100.0000 (99.3750)\tlr 0.000003\n",
            "epoch: [60/100][30/45]\ttime 0.126 (0.804)\tdata 0.000 (0.695)\teta 0:24:19\tloss 0.8548 (0.8227)\tacc 96.8750 (98.8542)\tlr 0.000003\n",
            "epoch: [60/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.521)\teta 0:18:54\tloss 0.8049 (0.8217)\tacc 100.0000 (98.9844)\tlr 0.000003\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0240 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.4%\n",
            "CMC curve\n",
            "Rank-1  : 89.9%\n",
            "Rank-5  : 95.4%\n",
            "Rank-10 : 97.0%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-60\"\n",
            "epoch: [61/100][10/45]\ttime 0.095 (2.187)\tdata 0.000 (2.071)\teta 1:05:13\tloss 0.7919 (0.8260)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [61/100][20/45]\ttime 0.095 (1.144)\tdata 0.000 (1.035)\teta 0:33:56\tloss 0.8862 (0.8263)\tacc 96.8750 (99.0625)\tlr 0.000000\n",
            "epoch: [61/100][30/45]\ttime 0.111 (0.797)\tdata 0.000 (0.690)\teta 0:23:30\tloss 0.8016 (0.8249)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [61/100][40/45]\ttime 0.079 (0.624)\tdata 0.000 (0.518)\teta 0:18:18\tloss 0.8370 (0.8203)\tacc 96.8750 (99.0625)\tlr 0.000000\n",
            "epoch: [62/100][10/45]\ttime 0.095 (2.200)\tdata 0.000 (2.090)\teta 1:03:59\tloss 0.8754 (0.8186)\tacc 93.7500 (98.7500)\tlr 0.000000\n",
            "epoch: [62/100][20/45]\ttime 0.111 (1.151)\tdata 0.000 (1.045)\teta 0:33:16\tloss 0.7883 (0.8151)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [62/100][30/45]\ttime 0.111 (0.803)\tdata 0.000 (0.697)\teta 0:23:05\tloss 0.9133 (0.8210)\tacc 93.7500 (98.6458)\tlr 0.000000\n",
            "epoch: [62/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.522)\teta 0:17:57\tloss 0.7739 (0.8175)\tacc 100.0000 (98.8281)\tlr 0.000000\n",
            "epoch: [63/100][10/45]\ttime 0.095 (2.201)\tdata 0.000 (2.086)\teta 1:02:21\tloss 0.8228 (0.8162)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [63/100][20/45]\ttime 0.111 (1.151)\tdata 0.000 (1.044)\teta 0:32:25\tloss 0.8574 (0.8194)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [63/100][30/45]\ttime 0.111 (0.802)\tdata 0.000 (0.696)\teta 0:22:27\tloss 0.8069 (0.8191)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [63/100][40/45]\ttime 0.094 (0.628)\tdata 0.000 (0.522)\teta 0:17:28\tloss 0.7851 (0.8180)\tacc 100.0000 (99.1406)\tlr 0.000000\n",
            "epoch: [64/100][10/45]\ttime 0.093 (2.211)\tdata 0.000 (2.099)\teta 1:00:58\tloss 0.8233 (0.8418)\tacc 100.0000 (98.4375)\tlr 0.000000\n",
            "epoch: [64/100][20/45]\ttime 0.095 (1.156)\tdata 0.000 (1.049)\teta 0:31:41\tloss 0.7954 (0.8356)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [64/100][30/45]\ttime 0.110 (0.807)\tdata 0.000 (0.700)\teta 0:21:59\tloss 0.7765 (0.8279)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [64/100][40/45]\ttime 0.094 (0.631)\tdata 0.000 (0.525)\teta 0:17:05\tloss 0.8094 (0.8274)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [65/100][10/45]\ttime 0.107 (2.208)\tdata 0.000 (2.091)\teta 0:59:14\tloss 0.8059 (0.8315)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [65/100][20/45]\ttime 0.094 (1.156)\tdata 0.000 (1.045)\teta 0:30:48\tloss 0.8267 (0.8284)\tacc 100.0000 (98.5938)\tlr 0.000000\n",
            "epoch: [65/100][30/45]\ttime 0.140 (0.806)\tdata 0.000 (0.697)\teta 0:21:22\tloss 0.7916 (0.8248)\tacc 100.0000 (98.8542)\tlr 0.000000\n",
            "epoch: [65/100][40/45]\ttime 0.080 (0.631)\tdata 0.000 (0.523)\teta 0:16:36\tloss 0.8232 (0.8217)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [66/100][10/45]\ttime 0.096 (2.182)\tdata 0.016 (2.074)\teta 0:56:55\tloss 0.8247 (0.8179)\tacc 96.8750 (99.0625)\tlr 0.000000\n",
            "epoch: [66/100][20/45]\ttime 0.111 (1.143)\tdata 0.000 (1.037)\teta 0:29:36\tloss 0.8338 (0.8192)\tacc 96.8750 (99.2188)\tlr 0.000000\n",
            "epoch: [66/100][30/45]\ttime 0.101 (0.797)\tdata 0.000 (0.691)\teta 0:20:31\tloss 0.8797 (0.8201)\tacc 96.8750 (98.8542)\tlr 0.000000\n",
            "epoch: [66/100][40/45]\ttime 0.079 (0.624)\tdata 0.000 (0.519)\teta 0:15:57\tloss 0.8072 (0.8192)\tacc 100.0000 (98.8281)\tlr 0.000000\n",
            "epoch: [67/100][10/45]\ttime 0.127 (2.240)\tdata 0.000 (2.094)\teta 0:56:45\tloss 0.8428 (0.8348)\tacc 96.8750 (98.4375)\tlr 0.000000\n",
            "epoch: [67/100][20/45]\ttime 0.095 (1.174)\tdata 0.000 (1.047)\teta 0:29:32\tloss 0.8198 (0.8254)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [67/100][30/45]\ttime 0.111 (0.821)\tdata 0.000 (0.699)\teta 0:20:32\tloss 0.8071 (0.8227)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [67/100][40/45]\ttime 0.079 (0.641)\tdata 0.000 (0.524)\teta 0:15:55\tloss 0.8784 (0.8217)\tacc 100.0000 (99.2969)\tlr 0.000000\n",
            "epoch: [68/100][10/45]\ttime 0.095 (2.201)\tdata 0.000 (2.087)\teta 0:54:06\tloss 0.7936 (0.8148)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [68/100][20/45]\ttime 0.095 (1.151)\tdata 0.000 (1.043)\teta 0:28:06\tloss 0.8168 (0.8191)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [68/100][30/45]\ttime 0.112 (0.804)\tdata 0.000 (0.696)\teta 0:19:30\tloss 0.7965 (0.8186)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [68/100][40/45]\ttime 0.064 (0.630)\tdata 0.000 (0.522)\teta 0:15:10\tloss 0.8143 (0.8178)\tacc 100.0000 (99.2969)\tlr 0.000000\n",
            "epoch: [69/100][10/45]\ttime 0.095 (2.202)\tdata 0.000 (2.089)\teta 0:52:29\tloss 0.7964 (0.8137)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [69/100][20/45]\ttime 0.095 (1.151)\tdata 0.000 (1.045)\teta 0:27:14\tloss 0.7997 (0.8225)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [69/100][30/45]\ttime 0.112 (0.803)\tdata 0.000 (0.697)\teta 0:18:51\tloss 0.8392 (0.8261)\tacc 100.0000 (98.5417)\tlr 0.000000\n",
            "epoch: [69/100][40/45]\ttime 0.080 (0.629)\tdata 0.000 (0.523)\teta 0:14:40\tloss 0.8127 (0.8249)\tacc 100.0000 (98.5938)\tlr 0.000000\n",
            "epoch: [70/100][10/45]\ttime 0.110 (2.199)\tdata 0.000 (2.084)\teta 0:50:46\tloss 0.8202 (0.8175)\tacc 100.0000 (99.6875)\tlr 0.000000\n",
            "epoch: [70/100][20/45]\ttime 0.111 (1.150)\tdata 0.000 (1.042)\teta 0:26:21\tloss 0.7877 (0.8175)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [70/100][30/45]\ttime 0.126 (0.802)\tdata 0.000 (0.695)\teta 0:18:14\tloss 0.8203 (0.8161)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [70/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.521)\teta 0:14:10\tloss 0.8160 (0.8151)\tacc 100.0000 (99.5312)\tlr 0.000000\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0293 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.4%\n",
            "CMC curve\n",
            "Rank-1  : 89.9%\n",
            "Rank-5  : 95.4%\n",
            "Rank-10 : 97.0%\n",
            "Rank-20 : 98.7%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-70\"\n",
            "epoch: [71/100][10/45]\ttime 0.094 (2.185)\tdata 0.000 (2.073)\teta 0:48:48\tloss 0.8223 (0.8118)\tacc 100.0000 (99.6875)\tlr 0.000000\n",
            "epoch: [71/100][20/45]\ttime 0.094 (1.143)\tdata 0.000 (1.037)\teta 0:25:19\tloss 0.8616 (0.8201)\tacc 96.8750 (99.2188)\tlr 0.000000\n",
            "epoch: [71/100][30/45]\ttime 0.110 (0.797)\tdata 0.000 (0.692)\teta 0:17:32\tloss 0.8623 (0.8244)\tacc 93.7500 (98.8542)\tlr 0.000000\n",
            "epoch: [71/100][40/45]\ttime 0.078 (0.624)\tdata 0.000 (0.519)\teta 0:13:37\tloss 0.8179 (0.8227)\tacc 96.8750 (98.9062)\tlr 0.000000\n",
            "epoch: [72/100][10/45]\ttime 0.096 (2.199)\tdata 0.000 (2.087)\teta 0:47:28\tloss 0.8054 (0.8128)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [72/100][20/45]\ttime 0.116 (1.151)\tdata 0.000 (1.043)\teta 0:24:38\tloss 0.8096 (0.8238)\tacc 96.8750 (98.5938)\tlr 0.000000\n",
            "epoch: [72/100][30/45]\ttime 0.096 (0.804)\tdata 0.000 (0.696)\teta 0:17:05\tloss 0.7882 (0.8210)\tacc 100.0000 (98.5417)\tlr 0.000000\n",
            "epoch: [72/100][40/45]\ttime 0.079 (0.629)\tdata 0.000 (0.522)\teta 0:13:16\tloss 0.7888 (0.8199)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [73/100][10/45]\ttime 0.095 (2.204)\tdata 0.000 (2.087)\teta 0:45:55\tloss 0.8153 (0.8171)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [73/100][20/45]\ttime 0.094 (1.155)\tdata 0.000 (1.044)\teta 0:23:52\tloss 0.8068 (0.8251)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [73/100][30/45]\ttime 0.110 (0.808)\tdata 0.016 (0.697)\teta 0:16:33\tloss 0.8113 (0.8267)\tacc 100.0000 (98.6458)\tlr 0.000000\n",
            "epoch: [73/100][40/45]\ttime 0.079 (0.632)\tdata 0.000 (0.522)\teta 0:12:50\tloss 0.8413 (0.8229)\tacc 96.8750 (98.8281)\tlr 0.000000\n",
            "epoch: [74/100][10/45]\ttime 0.111 (2.206)\tdata 0.016 (2.093)\teta 0:44:18\tloss 0.8392 (0.8207)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [74/100][20/45]\ttime 0.095 (1.154)\tdata 0.000 (1.046)\teta 0:22:59\tloss 0.8333 (0.8168)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [74/100][30/45]\ttime 0.111 (0.809)\tdata 0.000 (0.698)\teta 0:15:58\tloss 0.8268 (0.8164)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [74/100][40/45]\ttime 0.063 (0.633)\tdata 0.000 (0.524)\teta 0:12:23\tloss 0.8594 (0.8182)\tacc 96.8750 (99.2188)\tlr 0.000000\n",
            "epoch: [75/100][10/45]\ttime 0.099 (2.230)\tdata 0.000 (2.115)\teta 0:43:07\tloss 0.8358 (0.8313)\tacc 100.0000 (98.4375)\tlr 0.000000\n",
            "epoch: [75/100][20/45]\ttime 0.094 (1.166)\tdata 0.000 (1.058)\teta 0:22:20\tloss 0.8466 (0.8330)\tacc 96.8750 (97.9688)\tlr 0.000000\n",
            "epoch: [75/100][30/45]\ttime 0.110 (0.813)\tdata 0.000 (0.705)\teta 0:15:26\tloss 0.8066 (0.8271)\tacc 100.0000 (98.5417)\tlr 0.000000\n",
            "epoch: [75/100][40/45]\ttime 0.079 (0.635)\tdata 0.000 (0.529)\teta 0:11:57\tloss 0.7957 (0.8241)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [76/100][10/45]\ttime 0.095 (2.225)\tdata 0.000 (2.108)\teta 0:41:20\tloss 0.7829 (0.7992)\tacc 100.0000 (99.6875)\tlr 0.000000\n",
            "epoch: [76/100][20/45]\ttime 0.111 (1.164)\tdata 0.000 (1.056)\teta 0:21:26\tloss 0.9230 (0.8201)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [76/100][30/45]\ttime 0.111 (0.816)\tdata 0.000 (0.704)\teta 0:14:53\tloss 0.8513 (0.8170)\tacc 96.8750 (99.4792)\tlr 0.000000\n",
            "epoch: [76/100][40/45]\ttime 0.079 (0.638)\tdata 0.000 (0.529)\teta 0:11:32\tloss 0.7873 (0.8169)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [77/100][10/45]\ttime 0.095 (2.212)\tdata 0.000 (2.098)\teta 0:39:27\tloss 0.8089 (0.8330)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [77/100][20/45]\ttime 0.096 (1.158)\tdata 0.000 (1.049)\teta 0:20:27\tloss 0.7881 (0.8237)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [77/100][30/45]\ttime 0.110 (0.808)\tdata 0.000 (0.699)\teta 0:14:08\tloss 0.8863 (0.8246)\tacc 96.8750 (98.9583)\tlr 0.000000\n",
            "epoch: [77/100][40/45]\ttime 0.078 (0.633)\tdata 0.000 (0.525)\teta 0:10:57\tloss 0.7743 (0.8299)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [78/100][10/45]\ttime 0.096 (2.214)\tdata 0.000 (2.102)\teta 0:37:49\tloss 0.7983 (0.8204)\tacc 100.0000 (100.0000)\tlr 0.000000\n",
            "epoch: [78/100][20/45]\ttime 0.095 (1.158)\tdata 0.000 (1.051)\teta 0:19:35\tloss 0.8089 (0.8206)\tacc 100.0000 (99.5312)\tlr 0.000000\n",
            "epoch: [78/100][30/45]\ttime 0.112 (0.807)\tdata 0.016 (0.702)\teta 0:13:31\tloss 0.8335 (0.8238)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [78/100][40/45]\ttime 0.078 (0.631)\tdata 0.000 (0.527)\teta 0:10:28\tloss 0.7891 (0.8220)\tacc 100.0000 (98.9844)\tlr 0.000000\n",
            "epoch: [79/100][10/45]\ttime 0.095 (2.209)\tdata 0.000 (2.094)\teta 0:36:04\tloss 0.8581 (0.8142)\tacc 100.0000 (100.0000)\tlr 0.000000\n",
            "epoch: [79/100][20/45]\ttime 0.094 (1.154)\tdata 0.000 (1.047)\teta 0:18:39\tloss 0.7858 (0.8123)\tacc 100.0000 (100.0000)\tlr 0.000000\n",
            "epoch: [79/100][30/45]\ttime 0.111 (0.806)\tdata 0.000 (0.698)\teta 0:12:53\tloss 0.8104 (0.8126)\tacc 96.8750 (99.6875)\tlr 0.000000\n",
            "epoch: [79/100][40/45]\ttime 0.080 (0.631)\tdata 0.000 (0.524)\teta 0:09:59\tloss 0.7985 (0.8143)\tacc 100.0000 (99.6094)\tlr 0.000000\n",
            "epoch: [80/100][10/45]\ttime 0.111 (2.201)\tdata 0.000 (2.087)\teta 0:34:17\tloss 0.8316 (0.8260)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [80/100][20/45]\ttime 0.111 (1.151)\tdata 0.000 (1.043)\teta 0:17:44\tloss 0.7765 (0.8198)\tacc 100.0000 (99.5312)\tlr 0.000000\n",
            "epoch: [80/100][30/45]\ttime 0.111 (0.802)\tdata 0.000 (0.696)\teta 0:12:13\tloss 0.8047 (0.8179)\tacc 100.0000 (99.6875)\tlr 0.000000\n",
            "epoch: [80/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.522)\teta 0:09:28\tloss 0.7920 (0.8191)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0300 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.4%\n",
            "CMC curve\n",
            "Rank-1  : 89.5%\n",
            "Rank-5  : 95.4%\n",
            "Rank-10 : 97.0%\n",
            "Rank-20 : 98.7%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-80\"\n",
            "epoch: [81/100][10/45]\ttime 0.094 (2.199)\tdata 0.000 (2.080)\teta 0:32:36\tloss 0.8082 (0.8267)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [81/100][20/45]\ttime 0.094 (1.150)\tdata 0.000 (1.040)\teta 0:16:52\tloss 0.8333 (0.8207)\tacc 100.0000 (98.5938)\tlr 0.000000\n",
            "epoch: [81/100][30/45]\ttime 0.110 (0.804)\tdata 0.000 (0.693)\teta 0:11:39\tloss 0.8184 (0.8242)\tacc 100.0000 (98.6458)\tlr 0.000000\n",
            "epoch: [81/100][40/45]\ttime 0.079 (0.629)\tdata 0.000 (0.520)\teta 0:09:01\tloss 0.7677 (0.8203)\tacc 100.0000 (98.8281)\tlr 0.000000\n",
            "epoch: [82/100][10/45]\ttime 0.109 (2.224)\tdata 0.000 (2.109)\teta 0:31:19\tloss 0.8271 (0.8148)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [82/100][20/45]\ttime 0.112 (1.163)\tdata 0.000 (1.054)\teta 0:16:10\tloss 0.7969 (0.8143)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [82/100][30/45]\ttime 0.127 (0.811)\tdata 0.000 (0.703)\teta 0:11:09\tloss 0.7856 (0.8183)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [82/100][40/45]\ttime 0.079 (0.635)\tdata 0.000 (0.527)\teta 0:08:37\tloss 0.7930 (0.8154)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [83/100][10/45]\ttime 0.094 (2.215)\tdata 0.000 (2.102)\teta 0:29:31\tloss 0.8378 (0.8261)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [83/100][20/45]\ttime 0.111 (1.159)\tdata 0.000 (1.051)\teta 0:15:15\tloss 0.7899 (0.8179)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [83/100][30/45]\ttime 0.096 (0.807)\tdata 0.000 (0.701)\teta 0:10:29\tloss 0.7814 (0.8220)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [83/100][40/45]\ttime 0.078 (0.632)\tdata 0.000 (0.526)\teta 0:08:06\tloss 0.8325 (0.8190)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [84/100][10/45]\ttime 0.095 (2.213)\tdata 0.000 (2.096)\teta 0:27:51\tloss 0.8168 (0.8144)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [84/100][20/45]\ttime 0.095 (1.159)\tdata 0.000 (1.049)\teta 0:14:23\tloss 0.8150 (0.8117)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [84/100][30/45]\ttime 0.111 (0.808)\tdata 0.000 (0.700)\teta 0:09:54\tloss 0.8145 (0.8147)\tacc 100.0000 (99.1667)\tlr 0.000000\n",
            "epoch: [84/100][40/45]\ttime 0.095 (0.632)\tdata 0.000 (0.525)\teta 0:07:38\tloss 0.8266 (0.8165)\tacc 96.8750 (99.0625)\tlr 0.000000\n",
            "epoch: [85/100][10/45]\ttime 0.094 (2.211)\tdata 0.000 (2.095)\teta 0:26:09\tloss 0.8032 (0.8234)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [85/100][20/45]\ttime 0.095 (1.155)\tdata 0.000 (1.048)\teta 0:13:28\tloss 0.8326 (0.8198)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [85/100][30/45]\ttime 0.111 (0.809)\tdata 0.000 (0.699)\teta 0:09:17\tloss 0.7816 (0.8167)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [85/100][40/45]\ttime 0.078 (0.632)\tdata 0.000 (0.525)\teta 0:07:09\tloss 0.8062 (0.8175)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [86/100][10/45]\ttime 0.079 (2.196)\tdata 0.000 (2.085)\teta 0:24:20\tloss 0.8411 (0.8227)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [86/100][20/45]\ttime 0.094 (1.147)\tdata 0.000 (1.043)\teta 0:12:31\tloss 0.7929 (0.8187)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [86/100][30/45]\ttime 0.111 (0.799)\tdata 0.016 (0.696)\teta 0:08:35\tloss 0.8078 (0.8167)\tacc 100.0000 (99.1667)\tlr 0.000000\n",
            "epoch: [86/100][40/45]\ttime 0.079 (0.626)\tdata 0.000 (0.522)\teta 0:06:37\tloss 0.7939 (0.8223)\tacc 100.0000 (98.9844)\tlr 0.000000\n",
            "epoch: [87/100][10/45]\ttime 0.095 (2.216)\tdata 0.000 (2.102)\teta 0:22:53\tloss 0.8256 (0.8237)\tacc 100.0000 (98.4375)\tlr 0.000000\n",
            "epoch: [87/100][20/45]\ttime 0.095 (1.158)\tdata 0.000 (1.051)\teta 0:11:46\tloss 0.8208 (0.8183)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [87/100][30/45]\ttime 0.111 (0.808)\tdata 0.000 (0.701)\teta 0:08:04\tloss 0.7852 (0.8167)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [87/100][40/45]\ttime 0.096 (0.633)\tdata 0.000 (0.526)\teta 0:06:13\tloss 0.8186 (0.8149)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [88/100][10/45]\ttime 0.079 (2.212)\tdata 0.000 (2.101)\teta 0:21:11\tloss 0.9107 (0.8160)\tacc 90.6250 (98.4375)\tlr 0.000000\n",
            "epoch: [88/100][20/45]\ttime 0.095 (1.157)\tdata 0.000 (1.050)\teta 0:10:53\tloss 0.8332 (0.8150)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [88/100][30/45]\ttime 0.127 (0.808)\tdata 0.000 (0.700)\teta 0:07:28\tloss 0.8342 (0.8172)\tacc 100.0000 (98.9583)\tlr 0.000000\n",
            "epoch: [88/100][40/45]\ttime 0.063 (0.632)\tdata 0.000 (0.526)\teta 0:05:44\tloss 0.8472 (0.8194)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [89/100][10/45]\ttime 0.091 (2.216)\tdata 0.000 (2.102)\teta 0:19:34\tloss 0.8232 (0.8176)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [89/100][20/45]\ttime 0.097 (1.160)\tdata 0.000 (1.051)\teta 0:10:03\tloss 0.7819 (0.8201)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [89/100][30/45]\ttime 0.095 (0.810)\tdata 0.000 (0.701)\teta 0:06:53\tloss 0.8257 (0.8171)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [89/100][40/45]\ttime 0.095 (0.634)\tdata 0.000 (0.525)\teta 0:05:17\tloss 0.8334 (0.8166)\tacc 100.0000 (99.1406)\tlr 0.000000\n",
            "epoch: [90/100][10/45]\ttime 0.111 (2.224)\tdata 0.000 (2.105)\teta 0:17:58\tloss 0.7962 (0.8331)\tacc 100.0000 (98.1250)\tlr 0.000000\n",
            "epoch: [90/100][20/45]\ttime 0.095 (1.163)\tdata 0.000 (1.053)\teta 0:09:12\tloss 0.7874 (0.8280)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [90/100][30/45]\ttime 0.111 (0.811)\tdata 0.000 (0.702)\teta 0:06:16\tloss 0.9023 (0.8250)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [90/100][40/45]\ttime 0.079 (0.636)\tdata 0.000 (0.528)\teta 0:04:49\tloss 0.7796 (0.8218)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0280 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.1%\n",
            "CMC curve\n",
            "Rank-1  : 89.9%\n",
            "Rank-5  : 94.9%\n",
            "Rank-10 : 97.0%\n",
            "Rank-20 : 98.3%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-90\"\n",
            "epoch: [91/100][10/45]\ttime 0.096 (2.195)\tdata 0.000 (2.083)\teta 0:16:05\tloss 0.8408 (0.8115)\tacc 96.8750 (99.3750)\tlr 0.000000\n",
            "epoch: [91/100][20/45]\ttime 0.094 (1.149)\tdata 0.000 (1.042)\teta 0:08:14\tloss 0.7806 (0.8220)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [91/100][30/45]\ttime 0.095 (0.801)\tdata 0.000 (0.694)\teta 0:05:36\tloss 0.8168 (0.8266)\tacc 100.0000 (98.9583)\tlr 0.000000\n",
            "epoch: [91/100][40/45]\ttime 0.095 (0.626)\tdata 0.000 (0.521)\teta 0:04:16\tloss 0.8135 (0.8270)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [92/100][10/45]\ttime 0.094 (2.210)\tdata 0.000 (2.093)\teta 0:14:32\tloss 0.8129 (0.8228)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [92/100][20/45]\ttime 0.109 (1.156)\tdata 0.000 (1.047)\teta 0:07:25\tloss 0.7855 (0.8156)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [92/100][30/45]\ttime 0.110 (0.806)\tdata 0.000 (0.698)\teta 0:05:02\tloss 0.8223 (0.8157)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [92/100][40/45]\ttime 0.079 (0.631)\tdata 0.000 (0.524)\teta 0:03:50\tloss 0.8230 (0.8135)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [93/100][10/45]\ttime 0.093 (2.200)\tdata 0.000 (2.088)\teta 0:12:50\tloss 0.8244 (0.8090)\tacc 100.0000 (99.6875)\tlr 0.000000\n",
            "epoch: [93/100][20/45]\ttime 0.110 (1.150)\tdata 0.000 (1.044)\teta 0:06:30\tloss 0.8104 (0.8137)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [93/100][30/45]\ttime 0.127 (0.802)\tdata 0.000 (0.696)\teta 0:04:24\tloss 0.8115 (0.8176)\tacc 100.0000 (98.9583)\tlr 0.000000\n",
            "epoch: [93/100][40/45]\ttime 0.079 (0.628)\tdata 0.000 (0.522)\teta 0:03:20\tloss 0.8100 (0.8157)\tacc 100.0000 (99.1406)\tlr 0.000000\n",
            "epoch: [94/100][10/45]\ttime 0.095 (2.199)\tdata 0.000 (2.084)\teta 0:11:10\tloss 0.7771 (0.8099)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [94/100][20/45]\ttime 0.126 (1.153)\tdata 0.000 (1.042)\teta 0:05:40\tloss 0.7914 (0.8186)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [94/100][30/45]\ttime 0.111 (0.805)\tdata 0.000 (0.695)\teta 0:03:49\tloss 0.8126 (0.8234)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [94/100][40/45]\ttime 0.095 (0.630)\tdata 0.000 (0.521)\teta 0:02:53\tloss 0.7933 (0.8221)\tacc 96.8750 (99.1406)\tlr 0.000000\n",
            "epoch: [95/100][10/45]\ttime 0.095 (2.202)\tdata 0.000 (2.085)\teta 0:09:32\tloss 0.8185 (0.8277)\tacc 96.8750 (98.4375)\tlr 0.000000\n",
            "epoch: [95/100][20/45]\ttime 0.095 (1.151)\tdata 0.000 (1.042)\teta 0:04:47\tloss 0.8694 (0.8268)\tacc 96.8750 (98.7500)\tlr 0.000000\n",
            "epoch: [95/100][30/45]\ttime 0.111 (0.802)\tdata 0.000 (0.695)\teta 0:03:12\tloss 0.8195 (0.8290)\tacc 96.8750 (98.6458)\tlr 0.000000\n",
            "epoch: [95/100][40/45]\ttime 0.078 (0.628)\tdata 0.000 (0.522)\teta 0:02:24\tloss 0.8085 (0.8242)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [96/100][10/45]\ttime 0.095 (2.219)\tdata 0.000 (2.107)\teta 0:07:57\tloss 0.8020 (0.8344)\tacc 100.0000 (98.4375)\tlr 0.000000\n",
            "epoch: [96/100][20/45]\ttime 0.095 (1.160)\tdata 0.000 (1.053)\teta 0:03:57\tloss 0.8230 (0.8367)\tacc 100.0000 (98.1250)\tlr 0.000000\n",
            "epoch: [96/100][30/45]\ttime 0.126 (0.811)\tdata 0.016 (0.704)\teta 0:02:38\tloss 0.8096 (0.8266)\tacc 100.0000 (98.5417)\tlr 0.000000\n",
            "epoch: [96/100][40/45]\ttime 0.079 (0.635)\tdata 0.000 (0.528)\teta 0:01:57\tloss 0.8049 (0.8254)\tacc 100.0000 (98.7500)\tlr 0.000000\n",
            "epoch: [97/100][10/45]\ttime 0.096 (2.203)\tdata 0.000 (2.090)\teta 0:06:14\tloss 0.8435 (0.8208)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [97/100][20/45]\ttime 0.118 (1.152)\tdata 0.000 (1.046)\teta 0:03:04\tloss 0.8075 (0.8215)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [97/100][30/45]\ttime 0.111 (0.803)\tdata 0.000 (0.697)\teta 0:02:00\tloss 0.8422 (0.8219)\tacc 96.8750 (99.4792)\tlr 0.000000\n",
            "epoch: [97/100][40/45]\ttime 0.079 (0.629)\tdata 0.000 (0.523)\teta 0:01:28\tloss 0.8185 (0.8207)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [98/100][10/45]\ttime 0.095 (2.222)\tdata 0.000 (2.110)\teta 0:04:37\tloss 0.8015 (0.8175)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [98/100][20/45]\ttime 0.094 (1.162)\tdata 0.000 (1.055)\teta 0:02:13\tloss 0.7811 (0.8125)\tacc 100.0000 (98.9062)\tlr 0.000000\n",
            "epoch: [98/100][30/45]\ttime 0.111 (0.810)\tdata 0.000 (0.703)\teta 0:01:25\tloss 0.7969 (0.8159)\tacc 100.0000 (99.0625)\tlr 0.000000\n",
            "epoch: [98/100][40/45]\ttime 0.081 (0.633)\tdata 0.000 (0.527)\teta 0:01:00\tloss 0.8136 (0.8158)\tacc 96.8750 (98.8281)\tlr 0.000000\n",
            "epoch: [99/100][10/45]\ttime 0.096 (2.221)\tdata 0.000 (2.112)\teta 0:02:57\tloss 0.8126 (0.8100)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [99/100][20/45]\ttime 0.110 (1.162)\tdata 0.000 (1.056)\teta 0:01:21\tloss 0.7851 (0.8163)\tacc 100.0000 (99.2188)\tlr 0.000000\n",
            "epoch: [99/100][30/45]\ttime 0.110 (0.811)\tdata 0.000 (0.704)\teta 0:00:48\tloss 0.7972 (0.8135)\tacc 100.0000 (99.2708)\tlr 0.000000\n",
            "epoch: [99/100][40/45]\ttime 0.080 (0.634)\tdata 0.000 (0.528)\teta 0:00:31\tloss 0.8293 (0.8135)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [100/100][10/45]\ttime 0.095 (2.216)\tdata 0.000 (2.103)\teta 0:01:17\tloss 0.8000 (0.8102)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [100/100][20/45]\ttime 0.095 (1.159)\tdata 0.000 (1.052)\teta 0:00:28\tloss 0.7886 (0.8079)\tacc 100.0000 (99.3750)\tlr 0.000000\n",
            "epoch: [100/100][30/45]\ttime 0.110 (0.807)\tdata 0.000 (0.701)\teta 0:00:12\tloss 0.8160 (0.8107)\tacc 96.8750 (99.3750)\tlr 0.000000\n",
            "epoch: [100/100][40/45]\ttime 0.080 (0.631)\tdata 0.000 (0.526)\teta 0:00:03\tloss 0.8666 (0.8145)\tacc 93.7500 (99.0625)\tlr 0.000000\n",
            "=> Final test\n",
            "##### Evaluating endocv (source) #####\n",
            "Extracting features from query set ...\n",
            "Done, obtained 262-by-512 matrix\n",
            "Extracting features from gallery set ...\n",
            "Done, obtained 507-by-512 matrix\n",
            "Speed: 0.0299 sec/batch\n",
            "Computing distance matrix with metric=euclidean ...\n",
            "Computing CMC and mAP ...\n",
            "** Results **\n",
            "mAP: 74.5%\n",
            "CMC curve\n",
            "Rank-1  : 90.7%\n",
            "Rank-5  : 95.4%\n",
            "Rank-10 : 97.0%\n",
            "Rank-20 : 98.7%\n",
            "Checkpoint saved to \"log/osnet_dcn_x0_25_endocv\\model\\model.pth.tar-100\"\n",
            "Elapsed 0:53:32\n"
          ]
        }
      ],
      "source": [
        "engine.run(\n",
        "    save_dir=\"log/osnet_dcn_x0_25_endocv\",\n",
        "    max_epoch=100,\n",
        "    eval_freq=10,\n",
        "    print_freq=10\n",
        "    # if validate, enable 3 lines below\n",
        "    # test_only=True,\n",
        "    # visrank=True,\n",
        "    # visrank_topk=5\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-win_amd64.whl (14.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "Successfully installed numpy-1.24.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\~umpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Admin\\anaconda3\\envs\\endocv_311\\Lib\\site-packages\\~-mpy'.\n",
            "  You can safely remove it manually.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcED-rPxjqZ4",
        "outputId": "14883e63-3854-41c6-9387-b4f5345cc78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-12 09:14:06.015013: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744449246.036297    8326 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744449246.042681    8326 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Building train transforms ...\n",
            "+ resize to 256x128\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "Building test transforms ...\n",
            "+ resize to 256x128\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "=> Loading train (source) dataset\n",
            "/content/deep-person-reid/torchreid/data/datasets/image/endocv.py:34: UserWarning: The current data structure is deprecated. Please put data folders such as \"bounding_box_train\" under \"Market-1501-v15.09.15\".\n",
            "  warnings.warn(\n",
            "=> Loaded EndoCV\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    51 |     1454 |         8\n",
            "  query    |    51 |      262 |         8\n",
            "  gallery  |    51 |      507 |         1\n",
            "  ----------------------------------------\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> Loading test (target) dataset\n",
            "=> Loaded EndoCV\n",
            "  ----------------------------------------\n",
            "  subset   | # ids | # images | # cameras\n",
            "  ----------------------------------------\n",
            "  train    |    51 |     1454 |         8\n",
            "  query    |    51 |      262 |         8\n",
            "  gallery  |    51 |      507 |         1\n",
            "  ----------------------------------------\n",
            "\n",
            "\n",
            "  **************** Summary ****************\n",
            "  source            : ['endocv']\n",
            "  # source datasets : 1\n",
            "  # source ids      : 51\n",
            "  # source images   : 1454\n",
            "  # source cameras  : 8\n",
            "  target            : ['endocv']\n",
            "  *****************************************\n",
            "\n",
            "\n",
            "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x0_5_imagenet.pth\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['conv5.conv.weight', 'classifier.weight', 'classifier.bias']\n",
            "Backbone (conv1-conv4) frozen. Training only conv5, fc, and classifier.\n",
            "Successfully loaded pretrained weights from \"/content/drive/MyDrive/log/osnet_dcn_x0_5_endocv/model/osnet_dcn_x0_5_endocv_80.pt\"\n",
            "Visualizing activation maps for endocv ...\n"
          ]
        }
      ],
      "source": [
        "!python tools/visualize_actmap.py \\\n",
        "--root /content/deep-person-reid/reid-data \\\n",
        "-d endocv \\\n",
        "-m osnet_dcn_x0_5_endocv \\\n",
        "--weights /content/drive/MyDrive/log/osnet_dcn_x0_5_endocv/model/osnet_dcn_x0_5_endocv_80.pt \\\n",
        "--save-dir log/visactmap_osnet_dcn_x0_5_endocv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "QNAHB8AgL5wq",
        "outputId": "03cbe80a-cca1-4702-bfdf-3860a5d0fbe8"
      },
      "outputs": [
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-910201eb0253>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/log/osnet_dcn_x0_5_endocv/model/model.pth.tar-100'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "model = torch.load('/content/drive/MyDrive/log/osnet_dcn_x0_5_endocv/model/model.pth.tar-100',weights_only=True)\n",
        "\n",
        "\n",
        "# Lu m hnh vo tp pt\n",
        "torch.save(model, '/content/drive/MyDrive/log/osnet_dcn_x0_5_endocv/model/osnet_dcn_x0_5_endocv_80.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmNLKlAanOX-",
        "outputId": "60ea0112-e9f1-473d-8bd9-264bc1fc61af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: osnet_x0_25\n",
            "- params: 203,568\n",
            "- flops: 82,316,000\n",
            "Successfully loaded pretrained weights from \"/content/deep-person-reid/log/osnetx025/model/model.pth.tar-50\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
            "torch.Size([6, 512])\n"
          ]
        }
      ],
      "source": [
        "from torchreid.utils import FeatureExtractor\n",
        "\n",
        "extractor = FeatureExtractor(\n",
        "    model_name='osnet_x0_25',\n",
        "    model_path='/content/deep-person-reid/osnet_x0_25_model_endo.pt',\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "image_list = [\n",
        "    '/content/deep-person-reid/reid-data/endocv/query/0001_c1s2_000226_01.jpg',\n",
        "    '/content/deep-person-reid/reid-data/endocv/query/0002_c2s1_000205_01.jpg',\n",
        "    '/content/deep-person-reid/reid-data/endocv/query/0003_c3s1_000125_01.jpg',\n",
        "    '/content/deep-person-reid/reid-data/endocv/query/0004_c4s1_000137_01.jpg',\n",
        "    '/content/deep-person-reid/reid-data/endocv/query/0005_c5s2_000039_01.jpg',\n",
        "    '/content/deep-person-reid/reid-data/endocv/query/0006_c6s2_000014_01.jpg'\n",
        "]\n",
        "\n",
        "features = extractor(image_list)\n",
        "print(features.shape) # output (5, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSiBx64EL4_7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFyHD0A1mv7-",
        "outputId": "d85556c9-bd6c-4d11-cb4a-3eb1dc23982f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.2108, 0.0000, 0.5007,  ..., 0.0000, 0.3413, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.2481, 0.2577, 1.2484],\n",
            "        [3.1901, 0.0000, 0.9175,  ..., 0.0000, 0.2050, 0.0000],\n",
            "        [0.0000, 3.2798, 0.0000,  ..., 0.0000, 0.7325, 2.1805],\n",
            "        [0.0000, 0.7419, 0.0000,  ..., 1.4197, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 1.7335,  ..., 0.0000, 0.5269, 0.0000]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BaHt-solt1c"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/deep-person-reid/log/osnetx025_2/visrank_endocv /content/drive/MyDrive/logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchsummary\n",
            "  Using cached torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
            "Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: torchsummary\n",
            "Successfully installed torchsummary-1.5.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 32, 128, 64]           4,704\n",
            "       BatchNorm2d-2          [-1, 32, 128, 64]              64\n",
            "              ReLU-3          [-1, 32, 128, 64]               0\n",
            "         ConvLayer-4          [-1, 32, 128, 64]               0\n",
            "         MaxPool2d-5           [-1, 32, 64, 32]               0\n",
            "            Conv2d-6           [-1, 32, 64, 32]           1,024\n",
            "       BatchNorm2d-7           [-1, 32, 64, 32]              64\n",
            "              ReLU-8           [-1, 32, 64, 32]               0\n",
            "           Conv1x1-9           [-1, 32, 64, 32]               0\n",
            "           Conv2d-10           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-11           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-12           [-1, 32, 64, 32]              64\n",
            "             ReLU-13           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-14           [-1, 32, 64, 32]               0\n",
            "           Conv2d-15           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-16           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-17           [-1, 32, 64, 32]              64\n",
            "             ReLU-18           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-19           [-1, 32, 64, 32]               0\n",
            "           Conv2d-20           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-21           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-22           [-1, 32, 64, 32]              64\n",
            "             ReLU-23           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-24           [-1, 32, 64, 32]               0\n",
            "           Conv2d-25           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-26           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-27           [-1, 32, 64, 32]              64\n",
            "             ReLU-28           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-29           [-1, 32, 64, 32]               0\n",
            "           Conv2d-30           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-31           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-32           [-1, 32, 64, 32]              64\n",
            "             ReLU-33           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-34           [-1, 32, 64, 32]               0\n",
            "           Conv2d-35           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-36           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-37           [-1, 32, 64, 32]              64\n",
            "             ReLU-38           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-39           [-1, 32, 64, 32]               0\n",
            "           Conv2d-40           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-41           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-42           [-1, 32, 64, 32]              64\n",
            "             ReLU-43           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-44           [-1, 32, 64, 32]               0\n",
            "           Conv2d-45           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-46           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-47           [-1, 32, 64, 32]              64\n",
            "             ReLU-48           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-49           [-1, 32, 64, 32]               0\n",
            "           Conv2d-50           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-51           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-52           [-1, 32, 64, 32]              64\n",
            "             ReLU-53           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-54           [-1, 32, 64, 32]               0\n",
            "           Conv2d-55           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-56           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-57           [-1, 32, 64, 32]              64\n",
            "             ReLU-58           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-59           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-60             [-1, 32, 1, 1]               0\n",
            "           Conv2d-61              [-1, 2, 1, 1]              66\n",
            "             ReLU-62              [-1, 2, 1, 1]               0\n",
            "           Conv2d-63             [-1, 32, 1, 1]              96\n",
            "          Sigmoid-64             [-1, 32, 1, 1]               0\n",
            "      ChannelGate-65           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-66             [-1, 32, 1, 1]               0\n",
            "           Conv2d-67              [-1, 2, 1, 1]              66\n",
            "             ReLU-68              [-1, 2, 1, 1]               0\n",
            "           Conv2d-69             [-1, 32, 1, 1]              96\n",
            "          Sigmoid-70             [-1, 32, 1, 1]               0\n",
            "      ChannelGate-71           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-72             [-1, 32, 1, 1]               0\n",
            "           Conv2d-73              [-1, 2, 1, 1]              66\n",
            "             ReLU-74              [-1, 2, 1, 1]               0\n",
            "           Conv2d-75             [-1, 32, 1, 1]              96\n",
            "          Sigmoid-76             [-1, 32, 1, 1]               0\n",
            "      ChannelGate-77           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-78             [-1, 32, 1, 1]               0\n",
            "           Conv2d-79              [-1, 2, 1, 1]              66\n",
            "             ReLU-80              [-1, 2, 1, 1]               0\n",
            "           Conv2d-81             [-1, 32, 1, 1]              96\n",
            "          Sigmoid-82             [-1, 32, 1, 1]               0\n",
            "      ChannelGate-83           [-1, 32, 64, 32]               0\n",
            "           Conv2d-84          [-1, 128, 64, 32]           4,096\n",
            "      BatchNorm2d-85          [-1, 128, 64, 32]             256\n",
            "    Conv1x1Linear-86          [-1, 128, 64, 32]               0\n",
            "           Conv2d-87          [-1, 128, 64, 32]           4,096\n",
            "      BatchNorm2d-88          [-1, 128, 64, 32]             256\n",
            "    Conv1x1Linear-89          [-1, 128, 64, 32]               0\n",
            "          OSBlock-90          [-1, 128, 64, 32]               0\n",
            "           Conv2d-91           [-1, 32, 64, 32]           4,096\n",
            "      BatchNorm2d-92           [-1, 32, 64, 32]              64\n",
            "             ReLU-93           [-1, 32, 64, 32]               0\n",
            "          Conv1x1-94           [-1, 32, 64, 32]               0\n",
            "           Conv2d-95           [-1, 32, 64, 32]           1,024\n",
            "           Conv2d-96           [-1, 32, 64, 32]             288\n",
            "      BatchNorm2d-97           [-1, 32, 64, 32]              64\n",
            "             ReLU-98           [-1, 32, 64, 32]               0\n",
            "     LightConv3x3-99           [-1, 32, 64, 32]               0\n",
            "          Conv2d-100           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-101           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-102           [-1, 32, 64, 32]              64\n",
            "            ReLU-103           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-104           [-1, 32, 64, 32]               0\n",
            "          Conv2d-105           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-106           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-107           [-1, 32, 64, 32]              64\n",
            "            ReLU-108           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-109           [-1, 32, 64, 32]               0\n",
            "          Conv2d-110           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-111           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-112           [-1, 32, 64, 32]              64\n",
            "            ReLU-113           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-114           [-1, 32, 64, 32]               0\n",
            "          Conv2d-115           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-116           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-117           [-1, 32, 64, 32]              64\n",
            "            ReLU-118           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-119           [-1, 32, 64, 32]               0\n",
            "          Conv2d-120           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-121           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-122           [-1, 32, 64, 32]              64\n",
            "            ReLU-123           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-124           [-1, 32, 64, 32]               0\n",
            "          Conv2d-125           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-126           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-127           [-1, 32, 64, 32]              64\n",
            "            ReLU-128           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-129           [-1, 32, 64, 32]               0\n",
            "          Conv2d-130           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-131           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-132           [-1, 32, 64, 32]              64\n",
            "            ReLU-133           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-134           [-1, 32, 64, 32]               0\n",
            "          Conv2d-135           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-136           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-137           [-1, 32, 64, 32]              64\n",
            "            ReLU-138           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-139           [-1, 32, 64, 32]               0\n",
            "          Conv2d-140           [-1, 32, 64, 32]           1,024\n",
            "          Conv2d-141           [-1, 32, 64, 32]             288\n",
            "     BatchNorm2d-142           [-1, 32, 64, 32]              64\n",
            "            ReLU-143           [-1, 32, 64, 32]               0\n",
            "    LightConv3x3-144           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-145             [-1, 32, 1, 1]               0\n",
            "          Conv2d-146              [-1, 2, 1, 1]              66\n",
            "            ReLU-147              [-1, 2, 1, 1]               0\n",
            "          Conv2d-148             [-1, 32, 1, 1]              96\n",
            "         Sigmoid-149             [-1, 32, 1, 1]               0\n",
            "     ChannelGate-150           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-151             [-1, 32, 1, 1]               0\n",
            "          Conv2d-152              [-1, 2, 1, 1]              66\n",
            "            ReLU-153              [-1, 2, 1, 1]               0\n",
            "          Conv2d-154             [-1, 32, 1, 1]              96\n",
            "         Sigmoid-155             [-1, 32, 1, 1]               0\n",
            "     ChannelGate-156           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-157             [-1, 32, 1, 1]               0\n",
            "          Conv2d-158              [-1, 2, 1, 1]              66\n",
            "            ReLU-159              [-1, 2, 1, 1]               0\n",
            "          Conv2d-160             [-1, 32, 1, 1]              96\n",
            "         Sigmoid-161             [-1, 32, 1, 1]               0\n",
            "     ChannelGate-162           [-1, 32, 64, 32]               0\n",
            "AdaptiveAvgPool2d-163             [-1, 32, 1, 1]               0\n",
            "          Conv2d-164              [-1, 2, 1, 1]              66\n",
            "            ReLU-165              [-1, 2, 1, 1]               0\n",
            "          Conv2d-166             [-1, 32, 1, 1]              96\n",
            "         Sigmoid-167             [-1, 32, 1, 1]               0\n",
            "     ChannelGate-168           [-1, 32, 64, 32]               0\n",
            "          Conv2d-169          [-1, 128, 64, 32]           4,096\n",
            "     BatchNorm2d-170          [-1, 128, 64, 32]             256\n",
            "   Conv1x1Linear-171          [-1, 128, 64, 32]               0\n",
            "         OSBlock-172          [-1, 128, 64, 32]               0\n",
            "          Conv2d-173          [-1, 128, 64, 32]          16,384\n",
            "     BatchNorm2d-174          [-1, 128, 64, 32]             256\n",
            "            ReLU-175          [-1, 128, 64, 32]               0\n",
            "         Conv1x1-176          [-1, 128, 64, 32]               0\n",
            "       AvgPool2d-177          [-1, 128, 32, 16]               0\n",
            "          Conv2d-178           [-1, 48, 32, 16]           6,144\n",
            "     BatchNorm2d-179           [-1, 48, 32, 16]              96\n",
            "            ReLU-180           [-1, 48, 32, 16]               0\n",
            "         Conv1x1-181           [-1, 48, 32, 16]               0\n",
            "          Conv2d-182           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-183           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-184           [-1, 48, 32, 16]              96\n",
            "            ReLU-185           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-186           [-1, 48, 32, 16]               0\n",
            "          Conv2d-187           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-188           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-189           [-1, 48, 32, 16]              96\n",
            "            ReLU-190           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-191           [-1, 48, 32, 16]               0\n",
            "          Conv2d-192           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-193           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-194           [-1, 48, 32, 16]              96\n",
            "            ReLU-195           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-196           [-1, 48, 32, 16]               0\n",
            "          Conv2d-197           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-198           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-199           [-1, 48, 32, 16]              96\n",
            "            ReLU-200           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-201           [-1, 48, 32, 16]               0\n",
            "          Conv2d-202           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-203           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-204           [-1, 48, 32, 16]              96\n",
            "            ReLU-205           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-206           [-1, 48, 32, 16]               0\n",
            "          Conv2d-207           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-208           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-209           [-1, 48, 32, 16]              96\n",
            "            ReLU-210           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-211           [-1, 48, 32, 16]               0\n",
            "          Conv2d-212           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-213           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-214           [-1, 48, 32, 16]              96\n",
            "            ReLU-215           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-216           [-1, 48, 32, 16]               0\n",
            "          Conv2d-217           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-218           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-219           [-1, 48, 32, 16]              96\n",
            "            ReLU-220           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-221           [-1, 48, 32, 16]               0\n",
            "          Conv2d-222           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-223           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-224           [-1, 48, 32, 16]              96\n",
            "            ReLU-225           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-226           [-1, 48, 32, 16]               0\n",
            "          Conv2d-227           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-228           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-229           [-1, 48, 32, 16]              96\n",
            "            ReLU-230           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-231           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-232             [-1, 48, 1, 1]               0\n",
            "          Conv2d-233              [-1, 3, 1, 1]             147\n",
            "            ReLU-234              [-1, 3, 1, 1]               0\n",
            "          Conv2d-235             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-236             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-237           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-238             [-1, 48, 1, 1]               0\n",
            "          Conv2d-239              [-1, 3, 1, 1]             147\n",
            "            ReLU-240              [-1, 3, 1, 1]               0\n",
            "          Conv2d-241             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-242             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-243           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-244             [-1, 48, 1, 1]               0\n",
            "          Conv2d-245              [-1, 3, 1, 1]             147\n",
            "            ReLU-246              [-1, 3, 1, 1]               0\n",
            "          Conv2d-247             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-248             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-249           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-250             [-1, 48, 1, 1]               0\n",
            "          Conv2d-251              [-1, 3, 1, 1]             147\n",
            "            ReLU-252              [-1, 3, 1, 1]               0\n",
            "          Conv2d-253             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-254             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-255           [-1, 48, 32, 16]               0\n",
            "          Conv2d-256          [-1, 192, 32, 16]           9,216\n",
            "     BatchNorm2d-257          [-1, 192, 32, 16]             384\n",
            "   Conv1x1Linear-258          [-1, 192, 32, 16]               0\n",
            "          Conv2d-259          [-1, 192, 32, 16]          24,576\n",
            "     BatchNorm2d-260          [-1, 192, 32, 16]             384\n",
            "   Conv1x1Linear-261          [-1, 192, 32, 16]               0\n",
            "         OSBlock-262          [-1, 192, 32, 16]               0\n",
            "          Conv2d-263           [-1, 48, 32, 16]           9,216\n",
            "     BatchNorm2d-264           [-1, 48, 32, 16]              96\n",
            "            ReLU-265           [-1, 48, 32, 16]               0\n",
            "         Conv1x1-266           [-1, 48, 32, 16]               0\n",
            "          Conv2d-267           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-268           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-269           [-1, 48, 32, 16]              96\n",
            "            ReLU-270           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-271           [-1, 48, 32, 16]               0\n",
            "          Conv2d-272           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-273           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-274           [-1, 48, 32, 16]              96\n",
            "            ReLU-275           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-276           [-1, 48, 32, 16]               0\n",
            "          Conv2d-277           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-278           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-279           [-1, 48, 32, 16]              96\n",
            "            ReLU-280           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-281           [-1, 48, 32, 16]               0\n",
            "          Conv2d-282           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-283           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-284           [-1, 48, 32, 16]              96\n",
            "            ReLU-285           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-286           [-1, 48, 32, 16]               0\n",
            "          Conv2d-287           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-288           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-289           [-1, 48, 32, 16]              96\n",
            "            ReLU-290           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-291           [-1, 48, 32, 16]               0\n",
            "          Conv2d-292           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-293           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-294           [-1, 48, 32, 16]              96\n",
            "            ReLU-295           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-296           [-1, 48, 32, 16]               0\n",
            "          Conv2d-297           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-298           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-299           [-1, 48, 32, 16]              96\n",
            "            ReLU-300           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-301           [-1, 48, 32, 16]               0\n",
            "          Conv2d-302           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-303           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-304           [-1, 48, 32, 16]              96\n",
            "            ReLU-305           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-306           [-1, 48, 32, 16]               0\n",
            "          Conv2d-307           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-308           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-309           [-1, 48, 32, 16]              96\n",
            "            ReLU-310           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-311           [-1, 48, 32, 16]               0\n",
            "          Conv2d-312           [-1, 48, 32, 16]           2,304\n",
            "          Conv2d-313           [-1, 48, 32, 16]             432\n",
            "     BatchNorm2d-314           [-1, 48, 32, 16]              96\n",
            "            ReLU-315           [-1, 48, 32, 16]               0\n",
            "    LightConv3x3-316           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-317             [-1, 48, 1, 1]               0\n",
            "          Conv2d-318              [-1, 3, 1, 1]             147\n",
            "            ReLU-319              [-1, 3, 1, 1]               0\n",
            "          Conv2d-320             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-321             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-322           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-323             [-1, 48, 1, 1]               0\n",
            "          Conv2d-324              [-1, 3, 1, 1]             147\n",
            "            ReLU-325              [-1, 3, 1, 1]               0\n",
            "          Conv2d-326             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-327             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-328           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-329             [-1, 48, 1, 1]               0\n",
            "          Conv2d-330              [-1, 3, 1, 1]             147\n",
            "            ReLU-331              [-1, 3, 1, 1]               0\n",
            "          Conv2d-332             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-333             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-334           [-1, 48, 32, 16]               0\n",
            "AdaptiveAvgPool2d-335             [-1, 48, 1, 1]               0\n",
            "          Conv2d-336              [-1, 3, 1, 1]             147\n",
            "            ReLU-337              [-1, 3, 1, 1]               0\n",
            "          Conv2d-338             [-1, 48, 1, 1]             192\n",
            "         Sigmoid-339             [-1, 48, 1, 1]               0\n",
            "     ChannelGate-340           [-1, 48, 32, 16]               0\n",
            "          Conv2d-341          [-1, 192, 32, 16]           9,216\n",
            "     BatchNorm2d-342          [-1, 192, 32, 16]             384\n",
            "   Conv1x1Linear-343          [-1, 192, 32, 16]               0\n",
            "         OSBlock-344          [-1, 192, 32, 16]               0\n",
            "          Conv2d-345          [-1, 192, 32, 16]          36,864\n",
            "     BatchNorm2d-346          [-1, 192, 32, 16]             384\n",
            "            ReLU-347          [-1, 192, 32, 16]               0\n",
            "         Conv1x1-348          [-1, 192, 32, 16]               0\n",
            "       AvgPool2d-349           [-1, 192, 16, 8]               0\n",
            "          Conv2d-350            [-1, 64, 16, 8]          12,288\n",
            "     BatchNorm2d-351            [-1, 64, 16, 8]             128\n",
            "            ReLU-352            [-1, 64, 16, 8]               0\n",
            "         Conv1x1-353            [-1, 64, 16, 8]               0\n",
            "          Conv2d-354            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-355            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-356            [-1, 64, 16, 8]             128\n",
            "            ReLU-357            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-358            [-1, 64, 16, 8]               0\n",
            "          Conv2d-359            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-360            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-361            [-1, 64, 16, 8]             128\n",
            "            ReLU-362            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-363            [-1, 64, 16, 8]               0\n",
            "          Conv2d-364            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-365            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-366            [-1, 64, 16, 8]             128\n",
            "            ReLU-367            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-368            [-1, 64, 16, 8]               0\n",
            "          Conv2d-369            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-370            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-371            [-1, 64, 16, 8]             128\n",
            "            ReLU-372            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-373            [-1, 64, 16, 8]               0\n",
            "          Conv2d-374            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-375            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-376            [-1, 64, 16, 8]             128\n",
            "            ReLU-377            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-378            [-1, 64, 16, 8]               0\n",
            "          Conv2d-379            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-380            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-381            [-1, 64, 16, 8]             128\n",
            "            ReLU-382            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-383            [-1, 64, 16, 8]               0\n",
            "          Conv2d-384            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-385            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-386            [-1, 64, 16, 8]             128\n",
            "            ReLU-387            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-388            [-1, 64, 16, 8]               0\n",
            "          Conv2d-389            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-390            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-391            [-1, 64, 16, 8]             128\n",
            "            ReLU-392            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-393            [-1, 64, 16, 8]               0\n",
            "          Conv2d-394            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-395            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-396            [-1, 64, 16, 8]             128\n",
            "            ReLU-397            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-398            [-1, 64, 16, 8]               0\n",
            "          Conv2d-399            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-400            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-401            [-1, 64, 16, 8]             128\n",
            "            ReLU-402            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-403            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-404             [-1, 64, 1, 1]               0\n",
            "          Conv2d-405              [-1, 4, 1, 1]             260\n",
            "            ReLU-406              [-1, 4, 1, 1]               0\n",
            "          Conv2d-407             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-408             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-409            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-410             [-1, 64, 1, 1]               0\n",
            "          Conv2d-411              [-1, 4, 1, 1]             260\n",
            "            ReLU-412              [-1, 4, 1, 1]               0\n",
            "          Conv2d-413             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-414             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-415            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-416             [-1, 64, 1, 1]               0\n",
            "          Conv2d-417              [-1, 4, 1, 1]             260\n",
            "            ReLU-418              [-1, 4, 1, 1]               0\n",
            "          Conv2d-419             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-420             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-421            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-422             [-1, 64, 1, 1]               0\n",
            "          Conv2d-423              [-1, 4, 1, 1]             260\n",
            "            ReLU-424              [-1, 4, 1, 1]               0\n",
            "          Conv2d-425             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-426             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-427            [-1, 64, 16, 8]               0\n",
            "          Conv2d-428           [-1, 256, 16, 8]          16,384\n",
            "     BatchNorm2d-429           [-1, 256, 16, 8]             512\n",
            "   Conv1x1Linear-430           [-1, 256, 16, 8]               0\n",
            "          Conv2d-431           [-1, 256, 16, 8]          49,152\n",
            "     BatchNorm2d-432           [-1, 256, 16, 8]             512\n",
            "   Conv1x1Linear-433           [-1, 256, 16, 8]               0\n",
            "         OSBlock-434           [-1, 256, 16, 8]               0\n",
            "          Conv2d-435            [-1, 64, 16, 8]          16,384\n",
            "     BatchNorm2d-436            [-1, 64, 16, 8]             128\n",
            "            ReLU-437            [-1, 64, 16, 8]               0\n",
            "         Conv1x1-438            [-1, 64, 16, 8]               0\n",
            "          Conv2d-439            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-440            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-441            [-1, 64, 16, 8]             128\n",
            "            ReLU-442            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-443            [-1, 64, 16, 8]               0\n",
            "          Conv2d-444            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-445            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-446            [-1, 64, 16, 8]             128\n",
            "            ReLU-447            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-448            [-1, 64, 16, 8]               0\n",
            "          Conv2d-449            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-450            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-451            [-1, 64, 16, 8]             128\n",
            "            ReLU-452            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-453            [-1, 64, 16, 8]               0\n",
            "          Conv2d-454            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-455            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-456            [-1, 64, 16, 8]             128\n",
            "            ReLU-457            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-458            [-1, 64, 16, 8]               0\n",
            "          Conv2d-459            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-460            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-461            [-1, 64, 16, 8]             128\n",
            "            ReLU-462            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-463            [-1, 64, 16, 8]               0\n",
            "          Conv2d-464            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-465            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-466            [-1, 64, 16, 8]             128\n",
            "            ReLU-467            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-468            [-1, 64, 16, 8]               0\n",
            "          Conv2d-469            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-470            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-471            [-1, 64, 16, 8]             128\n",
            "            ReLU-472            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-473            [-1, 64, 16, 8]               0\n",
            "          Conv2d-474            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-475            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-476            [-1, 64, 16, 8]             128\n",
            "            ReLU-477            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-478            [-1, 64, 16, 8]               0\n",
            "          Conv2d-479            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-480            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-481            [-1, 64, 16, 8]             128\n",
            "            ReLU-482            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-483            [-1, 64, 16, 8]               0\n",
            "          Conv2d-484            [-1, 64, 16, 8]           4,096\n",
            "          Conv2d-485            [-1, 64, 16, 8]             576\n",
            "     BatchNorm2d-486            [-1, 64, 16, 8]             128\n",
            "            ReLU-487            [-1, 64, 16, 8]               0\n",
            "    LightConv3x3-488            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-489             [-1, 64, 1, 1]               0\n",
            "          Conv2d-490              [-1, 4, 1, 1]             260\n",
            "            ReLU-491              [-1, 4, 1, 1]               0\n",
            "          Conv2d-492             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-493             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-494            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-495             [-1, 64, 1, 1]               0\n",
            "          Conv2d-496              [-1, 4, 1, 1]             260\n",
            "            ReLU-497              [-1, 4, 1, 1]               0\n",
            "          Conv2d-498             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-499             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-500            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-501             [-1, 64, 1, 1]               0\n",
            "          Conv2d-502              [-1, 4, 1, 1]             260\n",
            "            ReLU-503              [-1, 4, 1, 1]               0\n",
            "          Conv2d-504             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-505             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-506            [-1, 64, 16, 8]               0\n",
            "AdaptiveAvgPool2d-507             [-1, 64, 1, 1]               0\n",
            "          Conv2d-508              [-1, 4, 1, 1]             260\n",
            "            ReLU-509              [-1, 4, 1, 1]               0\n",
            "          Conv2d-510             [-1, 64, 1, 1]             320\n",
            "         Sigmoid-511             [-1, 64, 1, 1]               0\n",
            "     ChannelGate-512            [-1, 64, 16, 8]               0\n",
            "          Conv2d-513           [-1, 256, 16, 8]          16,384\n",
            "     BatchNorm2d-514           [-1, 256, 16, 8]             512\n",
            "   Conv1x1Linear-515           [-1, 256, 16, 8]               0\n",
            "         OSBlock-516           [-1, 256, 16, 8]               0\n",
            "          Conv2d-517            [-1, 18, 16, 8]          41,490\n",
            "    DeformConv2d-518           [-1, 256, 16, 8]         590,080\n",
            "     BatchNorm2d-519           [-1, 256, 16, 8]             512\n",
            "            ReLU-520           [-1, 256, 16, 8]               0\n",
            "DeformableOSBlock-521           [-1, 256, 16, 8]               0\n",
            "AdaptiveAvgPool2d-522            [-1, 256, 1, 1]               0\n",
            "          Linear-523                  [-1, 512]         131,584\n",
            "     BatchNorm1d-524                  [-1, 512]           1,024\n",
            "            ReLU-525                  [-1, 512]               0\n",
            "          Linear-526                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 1,715,554\n",
            "Trainable params: 1,715,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 141.25\n",
            "Params size (MB): 6.54\n",
            "Estimated Total Size (MB): 148.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from __future__ import division, absolute_import\n",
        "import warnings\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.ops import DeformConv2d\n",
        "\n",
        "__all__ = [\n",
        "    'osnet_x1_0', 'osnet_x0_75', 'osnet_x0_5', 'osnet_x0_25', 'osnet_ibn_x1_0', 'osnet_x0_25_endocv', 'osnet_dcn_x0_5_endocv'\n",
        "]\n",
        "\n",
        "pretrained_urls = {\n",
        "    'osnet_x1_0':\n",
        "    'https://drive.google.com/uc?id=1LaG1EJpHrxdAxKnSCJ_i0u-nbxSAeiFY',\n",
        "    'osnet_x0_75':\n",
        "    'https://drive.google.com/uc?id=1uwA9fElHOk3ZogwbeY5GkLI6QPTX70Hq',\n",
        "    'osnet_x0_5':\n",
        "    'https://drive.google.com/uc?id=16DGLbZukvVYgINws8u8deSaOqjybZ83i',\n",
        "    'osnet_x0_25':\n",
        "    'https://drive.google.com/uc?id=1rb8UN5ZzPKRc_xvtHlyDh-cSz88YX9hs',\n",
        "    'osnet_ibn_x1_0':\n",
        "    'https://drive.google.com/uc?id=1sr90V6irlYYDd4_4ISU2iruoRG8J__6l',\n",
        "    'osnet_x0_25_endocv':\n",
        "    'https://drive.google.com/uc?id=1W8mz6skAUmg33zMVpWn6woJym7xGygjh',\n",
        "    'osnet_dcn_x0_5_endocv':\n",
        "    'https://drive.google.com/uc?id=16DGLbZukvVYgINws8u8deSaOqjybZ83i'\n",
        "}\n",
        "\n",
        "\n",
        "##########\n",
        "# Basic layers\n",
        "##########\n",
        "class ConvLayer(nn.Module):\n",
        "    \"\"\"Convolution layer (conv + bn + relu).\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        groups=1,\n",
        "        IN=False\n",
        "    ):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "            bias=False,\n",
        "            groups=groups\n",
        "        )\n",
        "        if IN:\n",
        "            self.bn = nn.InstanceNorm2d(out_channels, affine=True)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv1x1(nn.Module):\n",
        "    \"\"\"1x1 convolution + bn + relu.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, groups=1):\n",
        "        super(Conv1x1, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            1,\n",
        "            stride=stride,\n",
        "            padding=0,\n",
        "            bias=False,\n",
        "            groups=groups\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv1x1Linear(nn.Module):\n",
        "    \"\"\"1x1 convolution + bn (w/o non-linearity).\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Conv1x1Linear, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels, out_channels, 1, stride=stride, padding=0, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv3x3(nn.Module):\n",
        "    \"\"\"3x3 convolution + bn + relu.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, groups=1):\n",
        "        super(Conv3x3, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "            groups=groups\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LightConv3x3(nn.Module):\n",
        "    \"\"\"Lightweight 3x3 convolution.\n",
        "\n",
        "    1x1 (linear) + dw 3x3 (nonlinear).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(LightConv3x3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, out_channels, 1, stride=1, padding=0, bias=False\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels,\n",
        "            out_channels,\n",
        "            3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "            groups=out_channels\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "##########\n",
        "# Building blocks for omni-scale feature learning\n",
        "##########\n",
        "class ChannelGate(nn.Module):\n",
        "    \"\"\"A mini-network that generates channel-wise gates conditioned on input tensor.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        num_gates=None,\n",
        "        return_gates=False,\n",
        "        gate_activation='sigmoid',\n",
        "        reduction=16,\n",
        "        layer_norm=False\n",
        "    ):\n",
        "        super(ChannelGate, self).__init__()\n",
        "        if num_gates is None:\n",
        "            num_gates = in_channels\n",
        "        self.return_gates = return_gates\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(\n",
        "            in_channels,\n",
        "            in_channels // reduction,\n",
        "            kernel_size=1,\n",
        "            bias=True,\n",
        "            padding=0\n",
        "        )\n",
        "        self.norm1 = None\n",
        "        if layer_norm:\n",
        "            self.norm1 = nn.LayerNorm((in_channels // reduction, 1, 1))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Conv2d(\n",
        "            in_channels // reduction,\n",
        "            num_gates,\n",
        "            kernel_size=1,\n",
        "            bias=True,\n",
        "            padding=0\n",
        "        )\n",
        "        if gate_activation == 'sigmoid':\n",
        "            self.gate_activation = nn.Sigmoid()\n",
        "        elif gate_activation == 'relu':\n",
        "            self.gate_activation = nn.ReLU(inplace=True)\n",
        "        elif gate_activation == 'linear':\n",
        "            self.gate_activation = None\n",
        "        else:\n",
        "            raise RuntimeError(\n",
        "                \"Unknown gate activation: {}\".format(gate_activation)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        x = self.global_avgpool(x)\n",
        "        x = self.fc1(x)\n",
        "        if self.norm1 is not None:\n",
        "            x = self.norm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        if self.gate_activation is not None:\n",
        "            x = self.gate_activation(x)\n",
        "        if self.return_gates:\n",
        "            return x\n",
        "        return input * x\n",
        "\n",
        "\n",
        "class OSBlock(nn.Module):\n",
        "    \"\"\"Omni-scale feature learning block.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        IN=False,\n",
        "        bottleneck_reduction=4,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(OSBlock, self).__init__()\n",
        "        mid_channels = out_channels // bottleneck_reduction\n",
        "        self.conv1 = Conv1x1(in_channels, mid_channels)\n",
        "        self.conv2a = LightConv3x3(mid_channels, mid_channels)\n",
        "        self.conv2b = nn.Sequential(\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "        )\n",
        "        self.conv2c = nn.Sequential(\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "        )\n",
        "        self.conv2d = nn.Sequential(\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "            LightConv3x3(mid_channels, mid_channels),\n",
        "        )\n",
        "        self.gate = ChannelGate(mid_channels)\n",
        "        self.conv3 = Conv1x1Linear(mid_channels, out_channels)\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = Conv1x1Linear(in_channels, out_channels)\n",
        "        self.IN = None\n",
        "        if IN:\n",
        "            self.IN = nn.InstanceNorm2d(out_channels, affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x1 = self.conv1(x)\n",
        "        x2a = self.conv2a(x1)\n",
        "        x2b = self.conv2b(x1)\n",
        "        x2c = self.conv2c(x1)\n",
        "        x2d = self.conv2d(x1)\n",
        "        x2 = self.gate(x2a) + self.gate(x2b) + self.gate(x2c) + self.gate(x2d)\n",
        "        x3 = self.conv3(x2)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "        out = x3 + identity\n",
        "        if self.IN is not None:\n",
        "            out = self.IN(out)\n",
        "        return F.relu(out)\n",
        "\n",
        "\n",
        "class DeformableOSBlock(nn.Module):\n",
        "    \"\"\"Deformable convolution block for OSNet conv5.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(DeformableOSBlock, self).__init__()\n",
        "        self.offset_conv = nn.Conv2d(\n",
        "            in_channels, 2 * kernel_size * kernel_size, \n",
        "            kernel_size=kernel_size, stride=stride, padding=padding\n",
        "        )\n",
        "        self.deform_conv = DeformConv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size, \n",
        "            stride=stride, padding=padding\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        offset = self.offset_conv(x)\n",
        "        x = self.deform_conv(x, offset)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "##########\n",
        "# Network architecture\n",
        "##########\n",
        "class OSNet(nn.Module):\n",
        "    \"\"\"Omni-Scale Network.\n",
        "    \n",
        "    Reference:\n",
        "        - Zhou et al. Omni-Scale Feature Learning for Person Re-Identification. ICCV, 2019.\n",
        "        - Zhou et al. Learning Generalisable Omni-Scale Representations\n",
        "          for Person Re-Identification. TPAMI, 2021.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        blocks,\n",
        "        layers,\n",
        "        channels,\n",
        "        feature_dim=512,\n",
        "        loss='softmax',\n",
        "        IN=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(OSNet, self).__init__()\n",
        "        num_blocks = len(blocks)\n",
        "        assert num_blocks == len(layers)\n",
        "        assert num_blocks == len(channels) - 1\n",
        "        self.loss = loss\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "        # convolutional backbone\n",
        "        self.conv1 = ConvLayer(3, channels[0], 7, stride=2, padding=3, IN=IN)\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = self._make_layer(\n",
        "            blocks[0],\n",
        "            layers[0],\n",
        "            channels[0],\n",
        "            channels[1],\n",
        "            reduce_spatial_size=True,\n",
        "            IN=IN\n",
        "        )\n",
        "        self.conv3 = self._make_layer(\n",
        "            blocks[1],\n",
        "            layers[1],\n",
        "            channels[1],\n",
        "            channels[2],\n",
        "            reduce_spatial_size=True\n",
        "        )\n",
        "        self.conv4 = self._make_layer(\n",
        "            blocks[2],\n",
        "            layers[2],\n",
        "            channels[2],\n",
        "            channels[3],\n",
        "            reduce_spatial_size=False\n",
        "        )\n",
        "        self.conv5 = Conv1x1(channels[3], channels[3])\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        # fully connected layer\n",
        "        self.fc = self._construct_fc_layer(\n",
        "            self.feature_dim, channels[3], dropout_p=None\n",
        "        )\n",
        "        # identity classification layer\n",
        "        self.classifier = nn.Linear(self.feature_dim, num_classes)\n",
        "\n",
        "        self._init_params()\n",
        "\n",
        "    def _make_layer(\n",
        "        self,\n",
        "        block,\n",
        "        layer,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        reduce_spatial_size,\n",
        "        IN=False\n",
        "    ):\n",
        "        layers = []\n",
        "\n",
        "        layers.append(block(in_channels, out_channels, IN=IN))\n",
        "        for i in range(1, layer):\n",
        "            layers.append(block(out_channels, out_channels, IN=IN))\n",
        "\n",
        "        if reduce_spatial_size:\n",
        "            layers.append(\n",
        "                nn.Sequential(\n",
        "                    Conv1x1(out_channels, out_channels),\n",
        "                    nn.AvgPool2d(2, stride=2)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _construct_fc_layer(self, fc_dims, input_dim, dropout_p=None):\n",
        "        if fc_dims is None or fc_dims < 0:\n",
        "            self.feature_dim = input_dim\n",
        "            return None\n",
        "\n",
        "        if isinstance(fc_dims, int):\n",
        "            fc_dims = [fc_dims]\n",
        "\n",
        "        layers = []\n",
        "        for dim in fc_dims:\n",
        "            layers.append(nn.Linear(input_dim, dim))\n",
        "            layers.append(nn.BatchNorm1d(dim))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            if dropout_p is not None:\n",
        "                layers.append(nn.Dropout(p=dropout_p))\n",
        "            input_dim = dim\n",
        "\n",
        "        self.feature_dim = fc_dims[-1]\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _init_params(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu'\n",
        "                )\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def featuremaps(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, return_featuremaps=False):\n",
        "        x = self.featuremaps(x)\n",
        "        if return_featuremaps:\n",
        "            return x\n",
        "        v = self.global_avgpool(x)\n",
        "        v = v.view(v.size(0), -1)\n",
        "        if self.fc is not None:\n",
        "            v = self.fc(v)\n",
        "        if not self.training:\n",
        "            return v\n",
        "        y = self.classifier(v)\n",
        "        if self.loss == 'softmax':\n",
        "            return y\n",
        "        elif self.loss == 'triplet':\n",
        "            return y, v\n",
        "        else:\n",
        "            raise KeyError(\"Unsupported loss: {}\".format(self.loss))\n",
        "\n",
        "\n",
        "def init_pretrained_weights(model, key=''):\n",
        "    \"\"\"Initializes model with pretrained weights.\n",
        "    \n",
        "    Layers that don't match with pretrained layers in name or size are kept unchanged.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import errno\n",
        "    import gdown\n",
        "    from collections import OrderedDict\n",
        "\n",
        "    def _get_torch_home():\n",
        "        ENV_TORCH_HOME = 'TORCH_HOME'\n",
        "        ENV_XDG_CACHE_HOME = 'XDG_CACHE_HOME'\n",
        "        DEFAULT_CACHE_DIR = '~/.cache'\n",
        "        torch_home = os.path.expanduser(\n",
        "            os.getenv(\n",
        "                ENV_TORCH_HOME,\n",
        "                os.path.join(\n",
        "                    os.getenv(ENV_XDG_CACHE_HOME, DEFAULT_CACHE_DIR), 'torch'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        return torch_home\n",
        "\n",
        "    torch_home = _get_torch_home()\n",
        "    model_dir = os.path.join(torch_home, 'checkpoints')\n",
        "    try:\n",
        "        os.makedirs(model_dir)\n",
        "    except OSError as e:\n",
        "        if e.errno == errno.EEXIST:\n",
        "            # Directory already exists, ignore.\n",
        "            pass\n",
        "        else:\n",
        "            # Unexpected OSError, re-raise.\n",
        "            raise\n",
        "    filename = key + '_imagenet.pth'\n",
        "    cached_file = os.path.join(model_dir, filename)\n",
        "\n",
        "    if not os.path.exists(cached_file):\n",
        "      if key == 'osnet_x0_25_endocv':\n",
        "        filename = key + '.pth'\n",
        "        cached_file = os.path.join(model_dir, filename)\n",
        "        gdown.download(pretrained_urls[key], cached_file, quiet=False)\n",
        "      elif key == 'osnet_dcn_x0_5_endocv':\n",
        "        filename = 'osnet_x0_5_imagenet.pth'\n",
        "        cached_file = os.path.join(model_dir, filename)\n",
        "        gdown.download(pretrained_urls['osnet_x0_5'], cached_file, quiet=False)\n",
        "      else:\n",
        "        gdown.download(pretrained_urls[key], cached_file, quiet=False)\n",
        "\n",
        "    state_dict = torch.load(cached_file)\n",
        "    model_dict = model.state_dict()\n",
        "    new_state_dict = OrderedDict()\n",
        "    matched_layers, discarded_layers = [], []\n",
        "\n",
        "    for k, v in state_dict.items():\n",
        "        if k.startswith('module.'):\n",
        "            k = k[7:] # discard module.\n",
        "\n",
        "        if k in model_dict and model_dict[k].size() == v.size():\n",
        "            new_state_dict[k] = v\n",
        "            matched_layers.append(k)\n",
        "        else:\n",
        "            discarded_layers.append(k)\n",
        "\n",
        "    model_dict.update(new_state_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "\n",
        "    if len(matched_layers) == 0:\n",
        "        warnings.warn(\n",
        "            'The pretrained weights from \"{}\" cannot be loaded, '\n",
        "            'please check the key names manually '\n",
        "            '(** ignored and continue **)'.format(cached_file)\n",
        "        )\n",
        "    else:\n",
        "        print(\n",
        "            'Successfully loaded imagenet pretrained weights from \"{}\"'.\n",
        "            format(cached_file)\n",
        "        )\n",
        "        if len(discarded_layers) > 0:\n",
        "            print(\n",
        "                '** The following layers are discarded '\n",
        "                'due to unmatched keys or layer size: {}'.\n",
        "                format(discarded_layers)\n",
        "            )\n",
        "\n",
        "# nh ngha OSNet vi DCN\n",
        "class OSNetWithDCN(OSNet):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        blocks,\n",
        "        layers,\n",
        "        channels,\n",
        "        feature_dim=512,\n",
        "        loss='softmax',\n",
        "        IN=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(OSNetWithDCN, self).__init__(\n",
        "            num_classes, blocks, layers, channels, feature_dim, loss, IN, **kwargs\n",
        "        )\n",
        "        # Thay conv5 bng DeformableOSBlock\n",
        "        self.conv5 = DeformableOSBlock(channels[3], channels[3])\n",
        "        self._init_params()\n",
        "\n",
        "    def featuremaps(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)  # Dng DCN  y\n",
        "        return x\n",
        "\n",
        "\n",
        "##########\n",
        "# Instantiation\n",
        "##########\n",
        "def osnet_x1_0(num_classes=1000, pretrained=True, loss='softmax', **kwargs):\n",
        "    # standard size (width x1.0)\n",
        "    model = OSNet(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[64, 256, 384, 512],\n",
        "        loss=loss,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        init_pretrained_weights(model, key='osnet_x1_0')\n",
        "    return model\n",
        "\n",
        "\n",
        "def osnet_x0_75(num_classes=1000, pretrained=True, loss='softmax', **kwargs):\n",
        "    # medium size (width x0.75)\n",
        "    model = OSNet(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[48, 192, 288, 384],\n",
        "        loss=loss,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        init_pretrained_weights(model, key='osnet_x0_75')\n",
        "    return model\n",
        "\n",
        "\n",
        "def osnet_x0_5(num_classes=1000, pretrained=True, loss='softmax', **kwargs):\n",
        "    # tiny size (width x0.5)\n",
        "    model = OSNet(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[32, 128, 192, 256],\n",
        "        loss=loss,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        init_pretrained_weights(model, key='osnet_x0_5')\n",
        "    return model\n",
        "\n",
        "\n",
        "def osnet_x0_25(num_classes=1000, pretrained=True, loss='softmax', **kwargs):\n",
        "    # very tiny size (width x0.25)\n",
        "    model = OSNet(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[16, 64, 96, 128],\n",
        "        loss=loss,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        init_pretrained_weights(model, key='osnet_x0_25')\n",
        "    return model\n",
        "\n",
        "\n",
        "def osnet_x0_25_endocv(num_classes=1000, pretrained=True, loss='softmax', **kwargs):\n",
        "    # very tiny size (width x0.25)\n",
        "    model = OSNet(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[16, 64, 96, 128],\n",
        "        loss=loss,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        init_pretrained_weights(model, key='osnet_x0_25_endocv')\n",
        "    return model\n",
        "\n",
        "\n",
        "def osnet_ibn_x1_0(\n",
        "    num_classes=1000, pretrained=True, loss='softmax', **kwargs\n",
        "):\n",
        "    # standard size (width x1.0) + IBN layer\n",
        "    # Ref: Pan et al. Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net. ECCV, 2018.\n",
        "    model = OSNet(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[64, 256, 384, 512],\n",
        "        loss=loss,\n",
        "        IN=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        init_pretrained_weights(model, key='osnet_ibn_x1_0')\n",
        "    return model\n",
        "\n",
        "def osnet_dcn_x0_5_endocv(num_classes=1000, pretrained=True, loss='softmax', freeze_backbone=False, **kwargs):\n",
        "    model = OSNetWithDCN(\n",
        "        num_classes,\n",
        "        blocks=[OSBlock, OSBlock, OSBlock],\n",
        "        layers=[2, 2, 2],\n",
        "        channels=[32, 128, 192, 256],\n",
        "        loss=loss,\n",
        "        **kwargs\n",
        "    )\n",
        "    if pretrained:\n",
        "        #init_pretrained_weights(model, key='osnet_dcn_x0_5_endocv')  # Dng weights ca osnet_x1_0\n",
        "        init_pretrained_weights(model, key='osnet_x0_5')\n",
        "        if freeze_backbone:\n",
        "            # ng bng conv1, conv2, conv3, conv4 dddddd\n",
        "            for name, param in model.named_parameters():\n",
        "                if 'conv5' not in name and 'fc' not in name and 'classifier' not in name:\n",
        "                    param.requires_grad = False\n",
        "            print(\"Backbone (conv1-conv4) frozen. Training only conv5, fc, and classifier.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def main():\n",
        "    from torchsummary import summary\n",
        "    import torch\n",
        "\n",
        "    # Gi s bn  nh ngha osnet_dcn_x0_5_endocv  y\n",
        "    model = osnet_dcn_x0_5_endocv(num_classes=1000, pretrained=False)\n",
        "\n",
        "    # Chuyn sang GPU nu c\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Hin th cu trc vi u vo 3x256x128 (thng dng cho OSNet)\n",
        "    summary(model, input_size=(3, 256, 128))\n",
        "    \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "endocv_311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
